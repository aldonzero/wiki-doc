## 基础

***

###  MySQL 语句执行过程？

***

1. 客户端经历三次握手和MySQL的连接器进行TCP连接，连接建立后，连接器验证用户名和密码，连接器会获取用户的权限保存，后续用户的操作都会基于此权限进行逻辑判断。

2. 查询缓存，MySQL服务收到客户端的SQL语句会解析出第一个字段，查看是什么类型的的语句。

   - 如果是select语句，MySQL会先去（Query Cache）里查找缓存数据，看看之前有没有执行过这一命令。查询缓存是以k-v形式保存在内存中的，key为SQL查询语句，value为SQL语句查询的结果。

   - 如果查询的语句命中缓存，那么会直接返回value给客户端。如果查询的语句没有命中查询缓存，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中。

     > 对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了
     >
     > ​
     >
     > 这里说的查询缓存是 server 层的，也就是 MySQL 8.0 版本移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer pool。

3. 解析SQL

   - 词法分析，MySQL 会根据你输入的字符串识别出关键字出来，构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。
   - 语法分析，根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。

4. 执行SQL

   - prepare 阶段，也就是预处理阶段；**预处理器**检查SQL语句中的表或字段是否存在；将`select *` 中的 `*`符号，扩展为表上的所有列。

   - optimize 阶段，也就是优化阶段；**优化器**主要负责将 SQL 查询语句的执行方案确定下来，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。

   - execute 阶段，也就是执行阶段；**执行器**和存储引擎交互，交互是以记录为单位的。

     - 主键索引查询

     - 全表扫描

     - 索引下推

       > 索引下推能够减少**二级索引**在查询时的回表操作，提高查询的效率，因为它将 Server 层部分负责的事情，交给存储引擎层去处理了。
       >
       > 回表查询前先对二级索引进行进行判断，如果条件不成立则跳过该二级索引；如果成立则执行回表查询，将查询的记录返回给Server层。

### 存储结构

***

- db.opt，用来存储当前数据库的默认字符集和字符校验规则。
- t_order.frm ，保存t_order 的**表结构** 。
- t_order.ibd，保存 t_order 的**表数据** 。

#### 表空间

表空间由**段**（segment）、**区**（extent）、**页**（page）、行（row）组成。

1. 表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。
   - 索引段：存放 B + 树的非叶子节点的区的集合；
   - 数据段：存放 B + 树的叶子节点的区的集合；
   - 回滚段：存放的是回滚数据的区的集合， MVCC 利用了回滚段实现了多版本查询数据。
2. 在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就**使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了**。
3. 页是 InnoDB 存储引擎磁盘管理的最小单元，**InnoDB 的数据是按「页」为单位来读写的**，以页为单位，将其整体读入内存。
4. 数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。

![输入图片说明](https://foruda.gitee.com/images/1681717602585779093/a4762aa8_8616658.png "屏幕截图")

#### InnoDB行格式

InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。

##### COMPACT 

一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。

1. 记录的额外信息
   - 变长字段长度列表：变长字段在存储数据的时候，也要把数据占用的大小存起来，存到「变长字段长度列表」里面，读取数据的时候才能根据这个「变长字段长度列表」去读取对应长度的数据。其他 TEXT、BLOB 等变长字段也是这么实现的。
   - NULL 值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。用整数字节的位表示（1字节8位），如果1字节不够表示，则再创建1字节。
   - 记录头信息
     - delete_mask ：标识此条数据是否被删除。从这里可以知道，我们执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1。
     - next_record：下一条记录的位置。记录与记录之间是通过链表组织的。
     - record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录。

![输入图片说明](https://foruda.gitee.com/images/1681718123242119817/951957a4_8616658.png "屏幕截图")

> MySQL 规定除了 TEXT、BLOBs 这种大对象类型之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节。

## 索引

***

**索引**是帮助存储引擎快速获取数据的一种**数据结构** ，用于加速数据库表的数据检索。

> 虽然索引能提高查询效率，但是在针对写多读少的场景过多的索引可能会降低数据库的性能。

### 索引分类

***

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。

#### 按数据结构分类

从数据结构的角度来看，MySQL 常见索引有 B+Tree 索引、HASH 索引、Full-Text 索引。

主键索引和二级索引默认使用的是B+树索引。

B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是**按主键顺序存放**的。每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。

> B+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，这意味着从千万级的表查询目标数据最多需要 3-4 次磁盘 I/O，所以**B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。**


##### 索引的底层实现

Hash索引的底层实现
基于Hash表实现，对于每行数据都会根据索引列计算一个hash码，并将hash码存储在hash索引中，同时索引表中保存每行数据的指针。

B+Tree索引结构
B+Tree是一种多路平衡搜索树，所有值存储在叶子节点上，叶子节点左右相互连接形成双向链表，键值存储在非叶子节点上。


##### 为什么选择B+Tree 作为索引结构？

- Hash虽然能快速查询，但是不支持范围查询。
- 二叉树，在某些情况下会退化成链表，在这种情况相当于全表扫描；二叉树的层级比较深，磁盘I/O次数比较多；
- 平衡二叉树，虽然解决了退化成链表的的问题，但是仍然存在层级较深的问题，如果每个节点存放一页，磁盘I/O效率问题还是没有解决，导致搜索效率不足；
- 多路平衡查找树（Balance Tree），B Tree 能够很好的利用操作系统和磁盘的交互特性，相对平衡二叉树IO次数降低了很多，但是由于非叶子节点也会存储数据，相较于B+Tree，每个节点存储的索引更少，访问磁盘IO数会更多；
- B+ Tree，B+ Tree是B Tree的变种，每个非叶子节点只存储索引关键字，数据存储在叶子节点中，这样B+ Tree相对于B Tree的非叶子节点可以存储更多的关键字，降低层级，减少磁盘IO次数，提高效率，保证性能的稳定性。

### 按字段特性分类

从字段特性的角度来看，索引分为主键索引、唯一索引、普通索引、前缀索引。

#### 主键索引

**主键索引**就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。



#### 唯一索引

**唯一索引**建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。

#### 普通索引

**普通索引**就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。

#### 前缀索引

**前缀索引**是指对**字符类型字段**的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。

### 按字段的个数分

从字段个数的角度来看，索引分为单列索引、联合索引（复合索引）。

- 建立在单列上的索引称为单列索引，比如主键索引；
- 建立在多列上的索引称为联合索引；

#### 联合索引

通过将多个字段组合成一个索引，该索引就被称为联合索引。

在建立联合索引时，需要考虑列的顺序。联合索引的列顺序对查询的效率有很大的影响。

- 区分度高的列放在联合索引的前面，区分度低的列放在后面。区分度是指列中不同值的数量与总行数的比值，区分度高的列表示有较多的不同值，而区分度低的列表示有较少的不同值；
- 多条件组合查询是，用的多的放前面，用的少的放后面。

使用联合索引时，存在**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配。

如果联合索引包含多个列，那么只有在查询条件中使用最左侧的列时（即遵循最左匹配原则），才能使用该联合索引，否则将无法使用该索引。

例如，如果有一个联合索引包含两个列(A,B)，查询语句中只使用了B列，那么该联合索引将无法被使用，即使该索引包含B列，也不能被查询优化器所使用。而如果查询语句中只使用了A列，那么该联合索引将会被使用，因为查询条件使用了索引的最左侧列。

##### 联合索引失效

- 不遵循**最左匹配原则**

- 范围查询的字段可以用到联合索引，但范围查询字段后面的字段无法使用联合索引。

  > 联合索引`(a, b)`
  >
  > `where a > 1 and b = 2` , a可以用到联合索引，b无法用到联合索引，因为在二级索引记录中，a是有序的而b是无序的。
  >
  > `where a >= 1 and b = 2` ，a和b都可以用到联合索引，因为在a=1的范围中，b是有序的。
  >
  > `WHERE a BETWEEN 2 AND 8 AND b = 2` ，a和b都用到了联合索引。
  >
  > `WHERE alike 'j%' and b= 22 `，a和b都用到了联合索引，对于符合 a= j 的二级索引记录的范围里，b字段的值是「有序」的

### 索引失效

1. 索引字段左模糊匹配`%xx `，索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。

   > 如果`%xx `的查询字段`select x,id`是覆盖索引或主键，那么是对二级索引树全扫描，因为针对二级索引树存储的字段更少，全扫描就能查询到结果。
   >
   > 如果`%xx `的查询字段`select a,b`包含非索引字段，那么直接全表扫描。

2. 索引使用函数，如，`length(name)`，索引保存的关键字是索引字段的原始值，而不是函数计算后的值。

   > MySQL 8.0后可以针对函数计算后的值建立一个索引。
   >
   > `alter table t_user add key idx_name_length ((length(name)));`

3. 对索引表达式计算，如，`id + 1 = 10` ,和2中的原因相似，索引保存的字段是原始值，只能把索引字段的值取出来，然后一次进行表达式的计算来进行条件判断，因此采用的是全表扫描的方式。

4. 对隐式索引类型的转换，如索引字段`phone -varchar(30)` ,类型自动转换会使用函数，函数会使索引失效。

   > MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。
   >
   > `select * from t_user where phone = 1300000001;`
   >
   > 相当于
   >
   > `select * from t_user where CAST(phone AS signed int) = 1300000001;`

5. 索引非最左匹配，联合索引`(a,b,c)`在创建的时候，是先针对前一个字段排序后再对后面字段排序，即，先对`字段a`排序后，`字段b`在`字段a`排序的基础上再进行排序，`字段c`同样如此。

   > 因为MySQL中有查询优化器，所以Where 子句的顺序并不重要。
   >
   > MySQL5.6之后，当索引截断时会走索引下推，当查询条件`where a = 1 and c = 3`时，`字段a`会走索引，会再存储引擎中筛选出符合条件`c = 3`的数据后再返回给Server层，过滤掉大量不符合条件的数据，减少回表的次数。

6. where 字句中的or

   - 如果or前是条件列，or后是非索引列，索引会失效。因为or的含义是前后条件有一个成立即可，因此只有一个列是条件列是没有意义的。
   - 如果or前后都是索引列，那么会针对两个条件列分别扫描，将结果合并。

### 统计计数

1. `count(主键 id)`：InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来返回给 Server 层，Server 判断 id 不为空就按行累加。
2. `count(1)`：InnoDB 引擎遍历整张表但不取值，Server 层对于返回的每一行，放一个数字 1 进去，判断不为空就按行累加。
3. `count(字段)`：如果这个字段是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；如果这个字段定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加.
4. `count(*)`：不取值，按行累加。

> `count(字段) < count(主键id) < count(1) ≈ count(*)`，所以建议尽量使用 count(*)

#### count()优化

1. 如果业务对于统计个数不需要很精确，比如搜索引擎在搜索关键词的时候，给出的搜索结果条数是一个大概值，使用`explain select count(*) from t_order;`
2. 如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中,当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。



### 隔离级别

#### 

InnoDB 存储引擎支持事务，所以加锁分析是基于该存储引擎

* Read Uncommitted 级别，任何操作都不会加锁

* Read Committed 级别，增删改操作会加写锁（行锁），读操作不加锁

  在 Server 层过滤条件时发现不满足的记录会调用 unlock_row 方法释放该记录的行锁，保证最后只有满足条件的记录加锁，但是扫表过程中每条记录的**加锁操作不能省略**。所以对数据量很大的表做批量修改时，如果无法使用相应的索引（全表扫描），在 Server 过滤数据时就会特别慢，出现虽然没有修改某些行的数据，但是还是被锁住了的现象（锁表），这种情况同样适用于  RR

* Repeatable Read 级别，增删改操作会加写锁，读操作不加锁。因为读写锁不兼容，**加了读锁后其他事务就无法修改数据**，影响了并发性能，为了保证隔离性和并发性，MySQL 通过 MVCC 解决了读写冲突。RR 级别下的锁有很多种，锁机制章节详解

* Serializable 级别，读加共享锁，写加排他锁，读写互斥，使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差

  * 串行化：让所有事务按顺序单独执行，写操作会加写锁，读操作会加读锁
  * 可串行化：让所有操作相同数据的事务顺序执行，通过加锁实现



参考文章：https://tech.meituan.com/2014/08/20/innodb-lock.html



***



### 原子特性

#### 实现方式

原子性是指事务是一个不可分割的工作单位，事务的操作如果成功就必须要完全应用到数据库，失败则不能对数据库有任何影响。比如事务中一个 SQL 语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态

InnoDB 存储引擎提供了两种事务日志：redo log（重做日志）和 undo log（回滚日志）

* redo log 用于保证事务持久性
* undo log 用于保证事务原子性和隔离性

undo log 属于**逻辑日志**，根据每行操作进行记录，记录了 SQL 执行相关的信息，用来回滚行记录到某个版本

当事务对数据库进行修改时，InnoDB 会先记录对应的 undo log，如果事务执行失败或调用了 rollback 导致事务回滚，InnoDB 会根据 undo log 的内容**做与之前相反的操作**：

* 对于每个 insert，回滚时会执行 delete

* 对于每个 delete，回滚时会执行 insert

* 对于每个 update，回滚时会执行一个相反的 update，把数据修改回去



参考文章：https://www.cnblogs.com/kismetv/p/10331633.html



***



#### DML 解析

##### INSERT

乐观插入：当前数据页的剩余空间充足，直接将数据进行插入

悲观插入：当前数据页的剩余空间不足，需要进行页分裂，申请一个新的页面来插入数据，会造成更多的 redo log，undo log 影响不大

当向某个表插入一条记录，实际上需要向聚簇索引和所有二级索引都插入一条记录，但是 undo log **只针对聚簇索引记录**，在回滚时会根据聚簇索引去所有的二级索引进行回滚操作

roll_pointer 是一个指针，**指向记录对应的 undo log 日志**，一条记录就是一个数据行，行格式中的 roll_pointer 就指向 undo log



***



##### DELETE

插入到页面中的记录会根据 next_record 属性组成一个单向链表，这个链表称为正常链表，被删除的记录也会通过 next_record 组成一个垃圾链表，该链表中所占用的存储空间可以被重新利用，并不会直接清除数据

在页面 Page Header 中，PAGE_FREE 属性指向垃圾链表的头节点，删除的工作过程：

* 将要删除的记录的 delete_flag 位置为 1，其他不做修改，这个过程叫 **delete mark**

* 在事务提交前，delete_flag = 1 的记录一直都会处于中间状态

* 事务提交后，有专门的线程将 delete_flag = 1 的记录从正常链表移除并加入垃圾链表，这个过程叫 **purge**

  purge 线程在执行删除操作时会创建一个 ReadView，根据事务的可见性移除数据（隔离特性部分详解）

当有新插入的记录时，首先判断 PAGE_FREE 指向的头节点是否足够容纳新纪录：

* 如果可以容纳新纪录，就会直接重用已删除的记录的存储空间，然后让 PAGE_FREE 指向垃圾链表的下一个节点
* 如果不能容纳新纪录，就直接向页面申请新的空间存储，并不会遍历垃圾链表

重用已删除的记录空间，可能会造成空间碎片，当数据页容纳不了一条记录时，会判断将碎片空间加起来是否可以容纳，判断为真就会重新组织页内的记录：

* 开辟一个临时页面，将页内记录一次插入到临时页面，此时临时页面时没有碎片的
* 把临时页面的内容复制到本页，这样就解放出了内存碎片，但是会耗费很大的性能资源


****



##### UPDATE

执行 UPDATE 语句，对于更新主键和不更新主键有两种不同的处理方式

不更新主键的情况：

* 就地更新（in-place update），如果更新后的列和更新前的列占用的存储空间一样大，就可以直接在原记录上修改

* 先删除旧纪录，再插入新纪录，这里的删除不是 delete mark，而是直接将记录加入垃圾链表，并且修改页面的相应的控制信息，执行删除的线程不是 purge，是执行更新的用户线程，插入新记录时可能造成页空间不足，从而导致页分裂


更新主键的情况：

* 将旧纪录进行 delete mark，在更新语句提交后由 purge 线程移入垃圾链表
* 根据更新的各列的值创建一条新纪录，插入到聚簇索引中

在对一条记录修改前会**将记录的隐藏列 trx_id 和 roll_pointer 的旧值记录到当前 undo log 对应的属性中**，这样当前记录的 roll_pointer 指向当前 undo log 记录，当前 undo log 记录的 roll_pointer 指向旧的 undo log 记录，**形成一个版本链**

UPDATE、DELETE 操作产生的 undo 日志会用于其他事务的 MVCC 操作，所以不能立即删除，INSERT 可以删除的原因是 MVCC 是对现有数据的快照



***



#### 回滚日志

undo log 是采用段的方式来记录，Rollback Segement 称为回滚段，本质上就是一个类型是 Rollback Segement Header 的页面

每个回滚段中有 1024 个 undo slot，每个 slot 存放 undo 链表页面的头节点页号，每个链表对应一个叫 undo log segment 的段

* 在以前老版本，只支持 1 个 Rollback Segement，只能记录 1024 个 undo log segment
* MySQL5.5 开始支持 128 个 Rollback Segement，支持 128*1024 个 undo 操作

工作流程：

* 事务执行前需要到系统表空间第 5 号页面中分配一个回滚段（页），获取一个 Rollback Segement Header 页面的地址
* 回滚段页面有 1024 个 undo slot，首先去回滚段的两个 cached 链表获取缓存的 slot，缓存中没有就在回滚段页面中找一个可用的 undo slot 分配给当前事务
* 如果是缓存中获取的 slot，则该 slot 对应的 undo log segment 已经分配了，需要重新分配，然后从 undo log segment 中申请一个页面作为日志链表的头节点，并填入对应的 slot 中
* 每个事务 undo 日志在记录的时候**占用两个 undo 页面的组成链表**，分别为 insert undo 链表和 update undo 链表，链表的头节点页面为 first undo page 会包含一些管理信息，其他页面为 normal undo page

  说明：事务执行过程的临时表也需要两个 undo 链表，不和普通表共用，这些链表并不是事务开始就分配，而是按需分配




***



### 隔离特性

#### 实现方式

隔离性是指，事务内部的操作与其他事务是隔离的，多个并发事务之间要相互隔离，不能互相干扰

* 严格的隔离性，对应了事务隔离级别中的 serializable，实际应用中对性能考虑很少使用可串行化

* 与原子性、持久性侧重于研究事务本身不同，隔离性研究的是**不同事务**之间的相互影响

隔离性让并发情形下的事务之间互不干扰：

- 一个事务的写操作对另一个事务的写操作（写写）：锁机制保证隔离性
- 一个事务的写操作对另一个事务的读操作（读写）：MVCC 保证隔离性

锁机制：事务在修改数据之前，需要先获得相应的锁，获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁（详解见锁机制）



***



#### 并发控制

MVCC 全称 Multi-Version Concurrency Control，即多版本并发控制，用来**解决读写冲突的无锁并发控制**，可以在发生读写请求冲突时不用加锁解决，这个读是指的快照读（也叫一致性读或一致性无锁读），而不是当前读：

* 快照读：实现基于 MVCC，因为是多版本并发，所以快照读读到的数据不一定是当前最新的数据，有可能是历史版本的数据
* 当前读：又叫加锁读，读取数据库记录是当前**最新的版本**（产生幻读、不可重复读），可以对读取的数据进行加锁，防止其他事务修改数据，是悲观锁的一种操作，读写操作加共享锁或者排他锁和串行化事务的隔离级别都是当前读

数据库并发场景：

* 读-读：不存在任何问题，也不需要并发控制

* 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读

* 写-写：有线程安全问题，可能会存在脏写（丢失更新）问题

MVCC 的优点：

* 在并发读写数据库时，做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了并发读写的性能
* 可以解决脏读，不可重复读等事务隔离问题（加锁也能解决），但不能解决更新丢失问题（写锁会解决）

提高读写和写写的并发性能：

* MVCC + 悲观锁：MVCC 解决读写冲突，悲观锁解决写写冲突
* MVCC + 乐观锁：MVCC 解决读写冲突，乐观锁解决写写冲突



参考文章：https://www.jianshu.com/p/8845ddca3b23



***



#### 实现原理

##### 隐藏字段

实现原理主要是隐藏字段，undo日志，Read View 来实现的

InnoDB 存储引擎，数据库中的**聚簇索引**每行数据，除了自定义的字段，还有数据库隐式定义的字段：

* DB_TRX_ID：最近修改事务 ID，记录创建该数据或最后一次修改该数据的事务 ID
* DB_ROLL_PTR：回滚指针，**指向记录对应的 undo log 日志**，undo log 中又指向上一个旧版本的 undo log
* DB_ROW_ID：隐含的自增 ID（**隐藏主键**），如果数据表没有主键，InnoDB 会自动以 DB_ROW_ID 作为聚簇索引

![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MVCC版本链隐藏字段.png)





***



##### 版本链

undo log 是逻辑日志，记录的是每个事务对数据执行的操作，而不是记录的全部数据，要**根据 undo log 逆推出以往事务的数据**

undo log 的作用：

* 保证事务进行 rollback 时的原子性和一致性，当事务进行回滚的时候可以用 undo log 的数据进行恢复
* 用于 MVCC 快照读，通过读取 undo log 的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据

undo log 主要分为两种：

* insert undo log：事务在 insert 新记录时产生的 undo log，只在事务回滚时需要，并且在事务提交后可以被立即丢弃

* update undo log：事务在进行 update 或 delete 时产生的 undo log，在事务回滚时需要，在快照读时也需要。不能随意删除，只有在当前读或事务回滚不涉及该日志时，对应的日志才会被 purge 线程统一清除

每次对数据库记录进行改动，都会产生的新版本的 undo log，随着更新次数的增多，所有的版本都会被 roll_pointer 属性连接成一个链表，把这个链表称之为**版本链**，版本链的头节点就是当前的最新的 undo log，链尾就是最早的旧 undo log

说明：因为 DELETE 删除记录，都是移动到垃圾链表中，不是真正的删除，所以才可以通过版本链访问原始数据

<img src="https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MVCC版本链.png" style="zoom: 80%;" />

注意：undo 是逻辑日志，这里只是直观的展示出来

工作流程：

* 有个事务插入 persion 表一条新记录，name 为 Jerry，age 为 24
* 事务 1 修改该行数据时，数据库会先对该行加排他锁，然后先记录 undo log，然后修改该行 name 为 Tom，并且修改隐藏字段的事务 ID 为当前事务 1 的 ID（默认为 1 之后递增），回滚指针指向拷贝到 undo log 的副本记录，事务提交后，释放锁
* 以此类推


***



##### 读视图

Read View 是事务进行读数据操作时产生的读视图，该事务执行快照读的那一刻会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的 ID，用来做可见性判断，根据视图判断当前事务能够看到哪个版本的数据

注意：这里的快照并不是把所有的数据拷贝一份副本，而是由 undo log 记录的逻辑日志，根据库中的数据进行计算出历史数据

工作流程：将版本链的头节点的事务 ID（最新数据事务 ID，大概率不是当前线程）DB_TRX_ID 取出来，与系统当前活跃事务的 ID 对比进行可见性分析，不可见就通过 DB_ROLL_PTR 回滚指针去取出 undo log 中的下一个 DB_TRX_ID 比较，直到找到最近的满足可见性的 DB_TRX_ID，该事务 ID 所在的旧记录就是当前事务能看见的最新的记录

Read View 几个属性：

- m_ids：生成 Read View 时当前系统中活跃的事务 id 列表（未提交的事务集合，当前事务也在其中）
- min_trx_id：生成 Read View 时当前系统中活跃的最小的事务 id，也就是 m_ids 中的最小值（已提交的事务集合）
- max_trx_id：生成 Read View 时当前系统应该分配给下一个事务的 id 值，m_ids 中的最大值加 1（未开始事务）
- creator_trx_id：生成该 Read View 的事务的事务 id，就是判断该 id 的事务能读到什么数据

creator 创建一个 Read View，进行可见性算法分析：（解决了读未提交）

*  db_trx_id == creator_trx_id：表示这个数据就是当前事务自己生成的，自己生成的数据自己肯定能看见，所以此数据对 creator 是可见的
*  db_trx_id <  min_trx_id：该版本对应的事务 ID 小于 Read view 中的最小活跃事务 ID，则这个事务在当前事务之前就已经被提交了，对 creator 可见（因为比已提交的最大事务 ID 小的并不一定已经提交，所以应该判断是否在活跃事务列表）

*  db_trx_id >= max_trx_id：该版本对应的事务 ID 大于 Read view 中当前系统的最大事务 ID，则说明该数据是在当前 Read view 创建之后才产生的，对 creator 不可见
*  min_trx_id<= db_trx_id < max_trx_id：判断 db_trx_id 是否在活跃事务列表 m_ids 中
   * 在列表中，说明该版本对应的事务正在运行，数据不能显示（**不能读到未提交的数据**）
   * 不在列表中，说明该版本对应的事务已经被提交，数据可以显示（**可以读到已经提交的数据**）


***



##### 工作流程

表 user 数据

```sh
id		name		age
1		张三		   18	
```

Transaction 20：

```mysql
START TRANSACTION;	-- 开启事务
UPDATE user SET name = '李四' WHERE id = 1;
UPDATE user SET name = '王五' WHERE id = 1;
```

Transaction 60：

```mysql
START TRANSACTION;	-- 开启事务
-- 操作表的其他数据
```

![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MVCC工作流程1.png)

ID 为 0 的事务创建 Read View：

* m_ids：20、60
* min_trx_id：20
* max_trx_id：61
* creator_trx_id：0

![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MVCC工作流程2.png)

只有红框部分才复合条件，所以只有张三对应的版本的数据可以被看到



参考视频：https://www.bilibili.com/video/BV1t5411u7Fg



***



##### 二级索引

只有在聚簇索引中才有 trx_id 和 roll_pointer 的隐藏列，对于二级索引判断可见性的方式：

* 二级索引页面的 Page Header 中有一个 PAGE_MAX_TRX_ID 属性，代表修改当前页面的最大的事务 ID，SELECT 语句访问某个二级索引时会判断 ReadView 的 min_trx_id 是否大于该属性，大于说明该页面的所有属性对 ReadView 可见
* 如果属性判断不可见，就需要利用二级索引获取主键值进行**回表操作**，得到聚簇索引后按照聚簇索引的可见性判断的方法操作


***



#### RC RR

Read View 用于支持 RC（Read Committed，读已提交）和 RR（Repeatable Read，可重复读）隔离级别的实现，所以 **SELECT 在 RC 和 RR 隔离级别使用 MVCC 读取记录**

RR、RC 生成时机：

- RC 隔离级别下，每次读取数据前都会生成最新的 Read View（当前读）
- RR 隔离级别下，在第一次数据读取时才会创建 Read View（快照读）

RC、RR 级别下的 InnoDB 快照读区别

- RC 级别下，事务中每次快照读都会新生成一个 Read View，这就是在 RC 级别下的事务中可以看到别的事务提交的更新的原因

- RR 级别下，某个事务的对某条记录的**第一次快照读**会创建一个 Read View， 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，使用的是同一个 Read View，所以一个事务的查询结果每次都是相同的

  RR 级别下，通过 `START TRANSACTION WITH CONSISTENT SNAPSHOT` 开启事务，会在执行该语句后立刻生成一个 Read View，不是在执行第一条 SELECT 语句时生成（所以说 `START TRANSACTION` 并不是事务的起点，执行第一条语句才算起点）

解决幻读问题：

- 快照读：通过 MVCC 来进行控制的，在可重复读隔离级别下，普通查询是快照读，是不会看到别的事务插入的数据的，但是**并不能完全避免幻读**

  场景：RR 级别，T1 事务开启，创建 Read View，此时 T2 去 INSERT 新的一行然后提交，然后 T1 去 UPDATE 该行会发现更新成功，并且把这条新记录的 trx_id 变为当前的事务 id，所以对当前事务就是可见的。因为 **Read View 并不能阻止事务去更新数据，更新数据都是先读后写并且是当前读**，读取到的是最新版本的数据

- 当前读：通过 next-key 锁（行锁 + 间隙锁）来解决问题



## 锁机制

***

> 锁机制：数据库为了保证`数据的一致性`，在共享的资源被`并发访问`时变得安全有序所设计的一种规则
>
> 利用 MVCC 性质进行读取的操作叫`一致性读`，读取数据前加锁的操作叫`锁定读`



### 锁的分类

***

- **按操作分类：**
  - 共享锁：也叫读锁。对同一份数据，多个事务读操作可以同时加锁而不互相影响 ，但不能修改数据。

  - 排他锁：也叫写锁。当前的操作没有完成前，会阻断其他操作的读取和写入。

    > ps：共享锁主要是防止在读数据时，其他事务对数据进行修改。


- **按粒度分类：**
  - 行级锁：会锁定当前操作行，开销大，加锁慢；`会出现死锁`；锁定力度小，发生锁冲突概率低，并发度高，偏向 InnoDB。
  - 表级锁：会锁定整个表，开销小，加锁快；`不会出现死锁`；锁定力度大，发生锁冲突概率高，并发度最低，偏向 MyISAM。
  - 页级锁：锁的力度、发生冲突的概率和加锁开销介于表锁和行锁之间，`会出现死锁`，并发性能一般。

- **按使用方式分类：**
  - 悲观锁：每次查询数据时都认为别人会修改，很悲观，所以查询时加锁。
  - 乐观锁：每次查询数据时都认为别人不会修改，很乐观，但是更新时会判断一下在此期间别人有没有去更新这个数据。

- **意向锁：**

  - 意向共享锁 (IS Lock)：事务想要获得一个表中某几行的共享锁
  - 意向排他锁 (IX Lock)：事务想要获得一个表中某几行的排他锁。

查看当前请求锁信息：

```bash
show engine innodb status/G;
```



### MVCC

***

**一致性的非锁定行读(**consistent nonlocking read)是指InnoDB存储引擎**通过行多版本控制 (multi versioning)的方式**来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE、UPDATE操作，这时读取操作不会因此而会等待行上锁的释放，相反InnoDB存储引擎会去读取行的一个快照数据。 快照数据是指该行之前版本的数据，该实现是通过Undo段来实现。而Undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销此外，读取快照数据是不需要上锁的，因为没有必要对历史的数据进行修改。

对于快照数据的定义却不相同。

- 在Read Committed事务隔离级别下，对于快照数据非一致性读总是读取被锁定行的 **最新一份** 快照数据，在同一个事务中**多次读取的都是该行的最新版本数据**，无法解决脏读问题。
- 在Repeatable事务隔离级别下和Repeatable Read事务隔离级别下，对于快照数据非一致性读总是读取 **事务开始** 时的行数据版本。

> InnoDB存储引擎的SELECT操作使用一致性非锁定读。而MySQL的默认隔离级别是'REPEATABLE-READ'。

### 内存结构

***

对一条记录加锁的本质就是**在内存中**创建一个锁结构与之关联，结构包括

* 事务信息：锁对应的事务信息，`一个锁属于一个事务`

  > ❓ 一个锁属于一个事务，那么多个事务对共享锁的加锁流程是怎样的？多个事务同时拥有同一锁吗？

* 索引信息：对于行级锁，需要记录加锁的记录属于哪个索引

* 表锁和行锁信息：表锁记录着锁定的表，行锁记录了 Space ID 所在表空间、Page Number 所在的页号、n_bits 使用了多少比特

* type_mode：一个 32 比特的数，被分成 lock_mode、lock_type、rec_lock_type 三个部分
  * lock_mode：锁模式，记录是共享锁、排他锁、意向锁之类
  * lock_type：代表表级锁还是行级锁
  * rec_lock_type：代表行锁的具体类型和 is_waiting 属性，is_waiting = true 时表示当前事务尚未获取到锁，处于等待状态。事务获取锁后的锁结构是 is_waiting 为 false，释放锁时会检查是否与当前记录关联的锁结构，如果有就唤醒对应事务的线程

一个事务可能操作多条记录，为了节省内存，满足下面条件的锁使用同一个锁结构：

* 在同一个事务中的加锁操作
* 被加锁的记录在同一个页面中
* 加锁的类型是一样的
* 加锁的状态是一样的

### Server

***

MySQL 里面`表级别`的锁有两种：

- 表锁
- 元数据锁（meta data lock，MDL)

MDL 叫元数据锁，主要用来保护 MySQL 内部对象的元数据，保证数据读写的正确性，**当对一个表做增删改查的时候，加 MDL 读锁；当要对表做结构变更操作 DDL 的时候，加 MDL 写锁**，两种锁不相互兼容，所以可以保证 DDL、DML、DQL 操作的安全

> DDL 操作执行前会隐式提交当前会话的事务，因为 DDL 一般会在若干个特殊事务中完成，开启特殊事务前需要提交到其他事务

MDL 锁的特性：

* MDL 锁不需要显式使用，在访问一个表的时候会被`自动加上`，在事务开始时申请，整个事务提交后释放（执行完单条语句不释放）

* MDL 锁是在 Server 中实现，不是 InnoDB 存储引擎层能直接实现的锁

* MDL 锁还能实现其他粒度级别的锁，比如全局锁、库级别的锁、表空间级别的锁

`FLUSH TABLES WITH READ LOCK` 简称（FTWRL），全局读锁，让整个库处于只读状态，DDL DML 都被阻塞，工作流程：

1. 上全局读锁（lock_global_read_lock）
2. 清理表缓存（close_cached_tables）
3. 上全局 COMMIT 锁（make_global_read_lock_block_commit）

该命令主要用于备份工具做**一致性备份**，由于 FTWRL 需要持有两把全局的 MDL 锁，并且还要关闭所有表对象，因此杀伤性很大

### 加锁操作

- SELECT...FOR UPDATE

  对读取的行记录加一个X锁。其他事务想在这些行上加任何锁都会被阻塞。

- SELECT...LOCK IN SHARE MODE

  对读取的行记录加一个S锁。其他事务可以向被锁定的记录加S锁，但是对于加X锁，则会被阻塞。

### 锁问题

***

通过锁可以实现事务隔离性要求，使得事务并发工作，但也存在问题。

#### 1、丢失更新

以下情况可能会出现丢失更新：

(1) 事务T1查询一行数据，放入本地内存，并显示给一个终端用户User1

(2) 事务T2也查询该行数据，并将取得的数据显示给终端用户User2

(3) User1修改这行记录，更新数据库并提交

(4) User2修改这行记录，更新数据库并提交

![输入图片说明](https://foruda.gitee.com/images/1681286331052856236/364dd2f7_8616658.png "屏幕截图")

> mysql 默认的隔离级别是'REPEATABLE-READ'，在同一个事务中的查询结果是相同的。
>
> ps：个人认为是业务逻辑上判断存在问题，因为用`update`更新时，同一个数据只有一个事务能更新，其余事务会进行等待，超时会报`Lock wait timeout exceeded; try restarting transaction`。

**解决方案：**在读取数据的时候也加上排他锁

#### 2、脏读

脏读指的就是在不同的事务下，可以读到另外事务未提交的数据，简单来说，就是可以读到脏数据，`读未提交`。违反了数据库的隔离性。

> `脏数据`和`脏页`有所不同。
>
> 脏页指的是在缓冲池中已经被修改的页，但是还没有刷新到磁盘，即数据库实例内存中的页和磁盘的页中的数据是不一致的，当然在刷新到磁盘之前，日志都已经被写人了重做日志文件中。
>
> 脏数据，是指在缓冲池中被修改的数据，并且还没有被提交 (commit)。

#### 3、不可重复读

不可重复读，在同一事务中多次读取同一数据的结果不同，由于在第一个事务在多次读取数据的间隙，其他事务对数据进行了修改，造成第一个事务多次读取的数据不一致。违反了数据库事务一致性的要求。

InnoDB存储引擎中，通过使用Next-Key Lock算法来避免不可重复读的问题。在Next-KeyLock算法下，对于索引的扫描，不仅仅是锁住扫描到的索引，而且还锁住这些索引覆盖的范围 (gap)。因此对于这个范围内的插人都是不允许的。

### 阻塞

***

在InnoDB存储引擎的源代码中，用`Mutex数据结构`来实现锁。在访问资源前需要用mutex_enter函数进行申请，在资源访问或修改完毕后立即执行mutex_exit函数。当一个资源已被一个事务占有时，另一个事务执行mutex_enter函数会发生等待，这就是阻塞。阻塞并不是一件坏事，阻塞是为了保证事务可以并发并且正常运行。

默认情况下InnoDB存储引擎不会回滚超时引发的错误异常

### 死锁

***

InnoDB存储引擎有一个后台的锁监控线程，该线程负责查看可能的死锁问题，并自动告知用户。发现死锁后，InnoDB存储引擎会马上回滚一个事务。

### 锁升级

***

数据库可以把一个表的行锁升级为一个页锁，或者将页锁升级为表锁。

锁升级带来的一个问题却是，因为锁粒度的降低而导致并发性能的降低。

InnoDB存储引擎不存在锁升级的问题。在InnoDB存储引擎中，1个锁的开销与1000000个锁是一样的，都没有开销。



## 事务

***

事务用来保证数据库的完整性，可以将多个操作看作一个完整的操作，具有四个特性（ACID）。

- 原子性

  ​

- 一致性

  ​

- 隔离性

  ​

- 持久性

  ​

### 事务的实现

***

原子性、一致性、持久性通过数据库的redo和undo来完成。

#### redo

在InnoDB存储引擎中，事务日志通过`重做 (redo) 日志文件`和InoDB存储引擎的`日志缓冲(InnoDB Log Buffer)` 来实现。

- 当开始一个事务时，会记录该事务的一个LSN (LogSequence Number，日志序列号)。
- 当事务执行时，会往InnoDB存储引擎的日志缓冲里插入事务日志。
- 当事务提交时，必须将InnoDB存储引擎的日志缓冲写入磁盘(默认的实现即innodb_flush_log_at_trx_commit=1)。

在InnoDB存储引擎中`在写数据前，需要先写日志`。这种方式称为预写日志方式(Write-Ahead Logging，WAL)。

InnoDB存储引擎通过`预写日志(Write-Ahead Logging，WAL)`的方式来保证事务的完整性，即`在写数据前，需要先写日志`。这意味着磁盘上存储的数据页和内存缓冲池中的页是不同步的，对于内存缓冲池中页的修改，先是写入重做日志文件，然后再写入磁盘，因此是一种异步的方式。

#### undo

对数据库进行修改时，不但会产生redo，而且还会产生一定量的undo。

执行的事务或语句由于某种原因失败了，或者用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。与redo不同的是，redo存放在重做日志文件中，undo存放在数据库内部的一个特殊段(segment)中，这称为undo段(undo segment)，undo段位于共享表空间内。

### 事务的隔离级别

***

- READ UNCOMMITTED
- READ COMMITTED
- REPEATABLE READ
- SERIALIZABLE

InnoDB存储引擎默认的支持隔离级别是`REPEATABLE READ`，是与标SQL不同的是，InnoDB存储引擎在REPEATABLE READ事务隔离级别下，使用`Next-Key Lock锁`的算法，因此**避免幻读**的产生。所以说，InnoDB存储引擎在默认REPEATABLE READ的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE隔离级别。

### 分布式事务

***

InnoDB存储引擎支持XA事务，通过XA事务可以来支持分布式事务的实现。分布式事指的是允许多个独立的事务资源 (transactionalresources)参与一个全局的事务中。事务资源通常是关系型数据库系统，但也可以是其他类型的资源。全局事务要求在其中所有参与的事务要么都提交、要么都回滚，这对于事务原有的ACID要求又有了提高。另外,在使用分布式事务时，InnoDB存储引擎的事务隔离级别必须设置为SERIALIABLE。

分布式事务由一个或者多个**资源管理器** (Resource Managers)、一个**事务管理器**（Transaction Manager）以及一个**应用程序**(Application Program)组成。

- 资源管理器:提供访问事务资源的方法。通常一个数据库就是一个资源管理器。
- 事务管理器:协调参与全局事务中的各个事务。需要和参与全局事务中的所有资源管理器进行通信。
- 应用程序:定义事务的边界，指定全局事务中的操作。

分布式事务使用两段式提交(two-phase commit)的方式。

（1）在第一个阶段，所有参与全局事务的节点都开始准备 (PREPARE)，告诉事务管理器它们准备好提交了。

（2）第二个阶段，事务管理器告诉资源管理器执行ROLLBACK还是COMMIT。

如果任何一个节点显示不能提交，则所有的节点都被告知需要回滚。