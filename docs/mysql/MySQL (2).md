# 1. 基础知识



<img src="https://foruda.gitee.com/images/1690946279540409421/c8b386b9_8616658.png" style="zoom: 30%;" />





## 1.1 一条查询 SQL 是如何执行的？

如果表 T 中没有字段 k，而你执行了这个语句 `select * from T where k=1`, 那肯 定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？

### 1.1.1 课后问题答案

课后答案:分析器。Oracle 会在分析阶段判断语句是否正确，表是否存在，列是否存在等。猜测 MySQL 也这样。

为什么不是执行器？原因是这个时候才打开表获取数据，但是表的字段不是数据啊，是事先定义好的，所以可以直接读取的，不需要打开表。

《高性能 mysql》里提到**解析器**和**预处理器**。**解析器**处理语法和解析查询, 生成一课对应的解析树。 **预处理器**进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过 则生成新的解析树，再提交给优化器。

### 1.1.2 课后总结

1.MySQL 的框架有几个组件, 各是什么作用?

连接器：负责跟客户端建立连接、获取权限、维持和管理连接。

查询缓存：查询请求先访问缓存(key 是查询的语句，value 是查询的结果)。命中直接返回。不推荐使用缓存，更新会把缓存清除(关闭缓存：参数 query\_cache\_type 设置成 DEMAND)。

分析器：对 SQL 语句做解析，判断 sql 是否正确。

优化器：决定使用哪个索引，多表关联（join）的时候，决定各个表的连接顺序。

执行器：执行语句，先判断用户有无查询权限，使用表定义的存储引擎。



2.Server 层和存储引擎层各是什么作用?

Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等 多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引 擎。



3.you have an error in your SQL syntax 这个保存是在词法分析里还是在语法分析里报错?

语法分析



4.对于表的操作权限验证在哪里进行?

执行器



5.执行器的执行查询语句的流程是什么样的?

1）调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则 将这行存在结果集中；

2\)调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。

3）执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。



1.1.2 其它问题

**问题 1**：我创建了一个没有 select 权限的用户，执行 select \* from T where k=1，报错“select command denied”，并没有报错“unknown column”，是不是可以说明是在打开表之后才判断读取的列不存在？

**回答：**我觉得针对这个 sql，mysql 的执行逻辑应该是这样的。在分析器中分析出 unknown column。 不是立马返回给客户端，而是去执行器阶段验证该用户是否具有针对该表的操作权限，如果有。则返回 unkuown column,如果没有。则返回 select command denied. 这就跟作者写的，在缓存中查询到内容之后，也不能立马将 value 返回给客户端，而是还要去执行器 阶段验证一下该用户是否具有针对该表的操作权限，如果有，则将缓存中查询出的 value 返回给客户 端，如果没有，则提示用户 "针对该表操作的权限不够"。



## 1.2 一条更新 SQL 是如何执行的？

与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角： **redo log（重做日志）**和 **binlog（归档日志）**，也即物理日志 redo log 和逻辑日志 binlog。



**redo log** 用于保证 **crash-safe** 能力。innodb\_flush\_log\_at\_trx\_commit 这个参数设置成 1 的时候，表 示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以**保证 MySQL 异常重启之后数据不丢失**。



sync\_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建 议你设置成 1，这样可以**保证 MySQL 异常重启之后 binlog 不丢失**。



课后问题：

前面我说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么 在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？

**1.2.1 课后问题答案**

首先，是恢复数据丢失的时间，既然需要恢复，肯定是数据丢失了。如果一天一备份的话，只要找到这天的全备，加入这天某段时间的 binlog 来恢复，如果一周一备份，假设是周一，而你要恢复的数据是周日某个时间点，那就，需要全备+周一到周日某个时间点的全部 binlog 用来恢复，时间相比前者需要增加很多；看业务能忍受的程度。

其次，是数据库丢失，如果一周一备份的话，需要确保整个一周的 binlog 都完好无损，否则将无法恢复；而一天一备，只要保证这天的 binlog 都完好无损；当然这个可以通过校验，或者冗余等技术来实现，相比之下，上面那点更重要



1.2.2 课后总结

为该讲的内容总结了几个问题, 大家复习的时候可以先尝试回答这些问题检查自己的掌握程度:

1\. redo log 的概念是什么? 为什么会存在.

redo log 就类似酒馆里边的粉板，记录顾客的赊账情况，当酒馆不忙时，再将赊账情况进行更新。也就是说**将记录的更新情况先按顺序存储在磁盘**，等到空闲了，再更新到特定的记录上去，将 I/O 操作延迟执行了。



2\. 什么是 WAL(write-ahead log)机制, 好处是什么.

该机制的关键点就是**先写日志，再写磁盘**，也就是先写粉板，等不忙的时候再写账本。需要注意的是：**“先写日志” 也是先写磁盘**，只是**写日志是顺序写盘**，速度很快（好处）。 具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。



3\. redo log 为什么可以保证 crash safe 机制.



4\. binlog 的概念是什么, 起到什么作用, 可以做 crash safe 吗?

是逻辑日志，存储的是这个语句的原始逻辑，比如：给 ID=2 这一行的 c 字段加 1。不可以做 crash safe。



5\. binlog 和 redolog 的不同点有哪些?

● redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。

● redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。

● redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。



6\. 物理一致性和逻辑一致性各应该怎么理解?



7\. 执行器和 innoDB 在执行 update 语句时候的流程是什么样的?

（1）执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

（2）执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

（3）引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。

（4）执行器生成这个操作的 binlog，并把 binlog 写入磁盘。

（5）执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。



8\. 如果数据库误操作, 如何执行数据恢复?

当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据， 那你可以这么做：

● 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到**临时库**；

● 然后，从备份的时间点开始，将备份的 binlog 依次取出来，**重放到中午误删表之前的那个时刻**。 这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。



9\. 什么是两阶段提交, 为什么需要两阶段提交, 两阶段提交怎么保证数据库中两份日志间的逻辑一致性(什么叫逻辑一致性)?

两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。为了让两份日志之间的逻辑一致。



10\. 如果不是两阶段提交, 先写 redo log 和先写 bin log 两种情况各会遇到什么问题?

（1）**先写 redo log 后写 binlog**。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来， 所以恢复后这一行 c 的值是 1。 但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。 然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。

（2）**先写 binlog 后写 redo log**。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1， 与原库的值不同。



1.2.3 其它问题

**问题一**：redo log 记录的是这个行在这个页更新之后的状态，binlog 记录的是 sql 吗？

**回答**： Redo log 不是记录数据页“更新之后的状态”，而是记录这个页 “**做了什么改动**”。Binlog 有两种模式，**statement 格式**的话是记 sql 语句， **row 格式**会记录行的内容，记两条，更新前和更新后都有。



**问题二**：就算分两阶段，如果在提交 bin log，和提交 redo log 事务之间系统崩溃，是否也会出现日志不一样的情况

**回答**：不会了，我个人理解把 binlog 夹在 redo log 中间，就是为了保证如果 redo 提交前的任何失败， 都会带来回滚，binlog 的写入也应该不会成功，只有这样，才能保证两个一致



**问题三**：Bin log 用于记录了完整的逻辑记录，所有的逻辑记录在 bin log 里都能找到，所以在备份恢复时，是以 bin log 为基础，通过其记录的完整逻辑操作，备份出一个和原库完整的数据。

~~在两阶段提交时，若 redo log 写入成功，bin log 写入失败，则后续通过 bin log 恢复时，恢复的数 据将会缺失一部分。(如 redo log 执行了 update t set status = 1，此时原库的数据 status 已更新为 1， 而 bin log 写入失败，没有记录这一操作，后续备份恢复时，其 status = 0，导致数据不一致）。~~

若先写入 bin log，当 bin log 写入成功，而 redo log 写入失败时，原库中的 status 仍然是 0 ，但是当通过 bin log 恢复时，其记录的操作是 set status = 1，也会导致数据不一致。 其核心就是， **redo log 记录的，即使异常重启，都会刷新到磁盘**，而 **bin log 记录的， 则主要用于备份**。

**回答：**几乎全对，除了这个“两阶段提交时，若 redo log 写入成功，但 binlog 写入失败…”这句话。 实际上，**因为是两阶段提交，这时候 redolog 只是完成了 prepare, 而 binlog 又失败，那么事务本身会回滚，所以这个库里面 status 的值是 0**。如果通过 binlog 恢复出一个库，status 值也是 0。这样不算丢失，这样是合理的结果。



**问题四：**老师您好，我之前是做运维的，通过 binlog 恢复误操作的数据，但是实际上，我们会后知后觉，误删除一段时间了，才发现误删除，此时，我把之前误删除的 binlog 导入，再把误删除之后 binlog 导入，会出现问题，比如主键冲突，而且 binlog 导数据，不同模式下时间也有不同，但是一 般都是 row 模式，时间还是很久，有没什么方式，时间短且数据一致性强的方式

**回答**：其实恢复数据只能恢复到误删之前到一刻，误删之后的，不能只靠 binlog 来做，因为业务逻辑可能因为误删操作的行为，插入了逻辑错误的语句，所以之后的，跟业务一起，从业务快速补数据的。只靠 binlog 补出来的往往不完整



**问题五**：redo log 的机制看起来和 ring buffer 一样的； 另外有个疑问，如果在重启后，需要通过检查 binlog来确认 redo log中处于 prepare 的事务是否需要 commit，那是否不需要二阶段提交，直接以 binlog 的为准，如果 binlog 中不存在的， 就认为是需要回滚的。这个地方，是不是我漏了什么？

**回答**：文章中有提到“**binlog 没有被用来做崩溃恢复**”，历史上的原因是，这个是一开始就这么设计的， 所以不能只依赖 binlog。操作上的原因是，binlog 是可以关的，你如果有权限，可以 set sql\_log\_bin=0 关掉本线程的 binlog 日志。 所以只依赖 binlog 来恢复就靠不住。



**问题六**：

我再来说下自己的理解 。

1 、prepare 阶段  2、 写 binlog  3 、commit

当在 2 之前崩溃时

重启恢复：后发现没有 commit，回滚。

备份恢复：没有 binlog 。

一致

当在 3 之前崩溃

重启恢复：虽没有 commit，但满足 prepare 和 binlog 完整，所以重启后会自动 commit。

备份：有 binlog. 一致



**一个表只能有一个主键，但是主键可以由多个字段构成。**



## 1.3 事务隔离：为什么你改了我还看不见？



你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，**当没有事务再需要用到这些回滚日志时，回滚日志会被删除**。

什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。

基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据， 所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。



在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过**数据只有 20GB，而回滚段有 200GB 的库**。最终只好为了清理回滚段，重建整个库。

除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。 你可以在 information\_schema 库的 innodb\_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。

```sql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60 
```



留一个问题吧。现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？



**1.3.1 课后问题答案**

在开发过程中，**尽可能的减小事务范围（即让事务执行时间不要那么长，时间一长，数据变动多， 就得保存更多的回滚日志，这是为了保证事务在执行期间看到的数据在前后必须是一致的）**，少用长事务，如果无法避免，保证逻辑日志空间足够用，并且支持动态日志空间增长。监控 Innodb\_trx 表，发现长事务报警。

这个问题，我们可以从应用开发端和数据库端来看。

首先，从应用开发端来看：

1\. 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general\_log 开起来，然后随便跑一个业务逻辑，通过 general\_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。

2\. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。

3\. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX\_EXECUTION\_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？）

其次，从数据库端来看：

1\. 监控 information\_schema.Innodb\_trx 表，设置长事务阈值，超过就报警 / 或者 kill；

2\. Percona 的 pt-kill 这个工具不错，推荐使用；

3\. 在业务功能测试阶段要求输出所有的 general\_log，分析日志行为提前发现问题；

4\. 如果使用的是 MySQL 5.6 或者更新版本，把 innodb\_undo\_tablespaces 设置成 2（或更大的值）。 如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。



**1.3.2 课后总结**

1\. 事务的概念是什么? √

2\. mysql 的事务隔离级别读未提交, 读已提交, 可重复读, 串行各是什么意思? √

3\. 读已提交, 可重复读是怎么通过视图构建实现的? √

4\. 可重复读的使用场景举例? 对账的时候应该很有用? √

5\. 事务隔离是怎么通过 read-view(读视图)实现的?

6\. 并发版本控制(MCVV)的概念是什么, 是怎么实现的? √

7\. 使用长事务的弊病? 为什么使用长事务可能拖垮整个库? 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据， 所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。

8\. 事务的启动方式有哪几种?

9\. commit work and chain 的语法是做什么用的?

10\. 怎么查询各个表中的长事务?

11\. 如何避免长事务的出现?



**1.3.3 其它问题**

**问题 1：**

在可重复读的隔离级别下，如何理解**当系统里没有比这个回滚日志更早的 read-view 的时候**， 这个回滚日志就会被删除？ 这也是**尽量不要使用长事务**的主要原因。 

比如，在某个时刻（今天上午 9:00）开启了一个事务 A（对于可重复读隔离级别，此时一个视图 read-view A 也创建了），这是一个很长的事务…… 

事务 A 在今天上午 9:20 的时候，查询了一个记录 R1 的一个字段 f1 的值为 1…… 

今天上午 9:25 的时候，一个事务 B（随之而来的 read-view B）也被开启了，它更新了 R1.f1 的值为 2（同时也创建了一个由 2 到 1 的回滚日志），这是一个短事务，事务随后就被 commit 了。 

今天上午 9:30 的时候，一个事务 C（随之而来的 read-view C）也被开启了，它更新了 R1.f1 的值为 3（同时也创建了一个由 3 到 2 的回滚日志），这是一个短事务，事务随后就被 commit 了。 …… 

到了下午 3:00 了，长事务 A 还没有 commit，为了保证事务在执行期间看到的数据在前后必须是一 致的，那些老的事务视图、回滚日志就必须存在了，这就占用了大量的存储空间。 源于此，我们应该尽量不要使用长事务。



