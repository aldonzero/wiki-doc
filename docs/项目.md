### 登录

用户在登录时会进行零次加密（前端使用固定）

### 分布式session

我们的秒杀服务，实际的应用可能不止部署在一个服务器上，而是分布式的多台服务器，这时候假如用户登录是在第一个服务器，第一个请求到了第一台服务器，但是第二个请求到了第二个服务器，那么用户的 session 信息就丢失了。

解决：session 同步，无论访问那一台服务器，session 都可以取得到。

本系统解决思路：
用户登录成功之后，给这个用户生成一个 sessionId(即，用 uuid 生成 token 来标识这个用户)，写到cookie 中，传递给客户端，并且将这个 token 存储在 Redis 中。然后客户端在随后的访问中，都在 cookie中上传这个 token，然后服务端拿到这个 token 之后，就根据这个 token 来取得对应的 session 信息。

使用 uuid 随机生成一个 token，然后以该 token 为 key，用户信息做 value 存储进 Redis 中

延长cookie的有效期

每次请求返回的response中加入token

### 数据库设计

数据库一般不使用自增 ID，也不使用 UUID 随机生成，而是使用 Twitter 的snowflake 算法生成的自增 ID



### 超卖问题

因为数据库对于多个线程（多个用户秒杀同一商品，每个用户只有一个请求）访问同一行会自动加一个锁。

1.数据库加唯一索引：防止用户重复购买。
2.SQL 加库存数量判断：防止库存变负数。

### 多次提交秒杀问题

如果是同一个用户多次秒杀，怎么办？一个用户有两个秒杀请求（一般不会产生，因为会给用户输入一个验证码），发现库存都为 10 是足够的，去减库存，是可以减成功的。解决办
法：在 miaosha_order 表中设置商品 id 的唯一索引，可以在生成订单的时候，防止用户秒杀同一商品多次。

小优化：将生成的订单插入缓存，这样在判断是否重复秒杀的时候就可以不用去查询数据库了。



###  **redis 预减库存，rabbitmq 异步下单**


**问题：**
 针对秒杀的业务场景，在大并发下，仅仅依靠页面缓存、对象缓存或者页面静态化等还是远远不够。数据库压力还是很大，所以需要异步下单，如果业务执行时间比较长，那么异步是最好的解决办法，但会带来一些额外的程序上的复杂性。

**思考：**
如何解决用户不断点击秒杀按钮，Redis 库存不断扣减的问题？

**回答：**在 Redis 里边缓存用户的秒杀记录，在 Redis 预减库存前进行判断用户是否秒杀过。秒杀结束后，删除秒杀记录。

Redis 如何解决和数据库出现库存不一致问题？

**回答：**因为没有查库存操作，只有扣减库存操作，又因为 redis 是单线程，所以不会出现并发扣减库存时的问题，唯一的一个问题是扣减多了怎么办？参考上一题的回答。

如何解决超卖问题？（超卖问题出现在 RabbitMQ 的多个消费者同时消费队列，执行扣减库存时出现）消息队列，异步下单，扣减库存。因为秒杀的商品不会很多，消费者一个一个去消费就不会出现超卖问题，而且如果有多个商品进行秒杀的话，这几个商品都建立一个队列，并不影响相互之间的库存扣减。

**思路：**
1.系统初始化，Redis 预加载商品库存。
2.秒杀开始，用户点击秒杀按钮，后台接收到秒杀请求，先判断用户是否登录->再判断是否秒杀过商品->Redis 预减库存并将用户秒杀记录存入缓存，如果库存已经到达临界值的时候，就不需要继续请求下去，直接返回失败，即防止了后面的大量请求无需给系统带来压力。
3.将秒杀请求放入消息队列，同时给前端返回一个 0，即表示正在排队中。（返回的并不是失败或者成功，此时还不能判断）
4.前端接收到数据后，显示排队中，并根据商品 id 轮询请求服务器（考虑 200ms 轮询一次）。
5.后端 RabbitMQ 监听秒杀 MIAOSHA_QUEUE 的这名字的通道，如果有消息过来，获取到传入的信息，执行真正的秒杀之前，要判断数据库的库存，判断是否重复秒杀，然后执行秒杀事务（秒杀事务是一个原子操作：库存减 1，下订单，写入秒杀订单）。
6.此时，前端根据商品 id 轮询请求接口 MiaoshaResult,查看是否生成了商品订单，如果请求返回-1代表秒杀失败，返回 0 代表排队中，返回>0 代表商品 id 说明秒杀成功。
返回结果说明：
前端会根据后端返回的值来判断是秒杀结果。
 -1 ：库存不足秒杀失败
 0 ：排队中，继续轮询

### 扣减库存如何保证线程安全的

### 假设缓存失效，所有请求都到数据库中去了，应该怎么做？

已经缓存击穿了，应该怎么拯救

可以做一些兜底的本地缓存

### 有做限流吗

如果请求很火爆也是会出现问题的

限流组件，限流策略

### 用户的恶意请求，怎么避免

### 缓存的数据是如何落库的

### 秒杀接口优化，思路：减少数据库访问

1.系统初始化，把商品库存数量加载到 Redis
2.收到请求，Redis 预减库存，库存不足，直接返回（好处：假设只有 10 个商品，10 个请求过来，
第 11 个就返回了，大大减少了后面访问数据库的压力），否则进入 3
3.请求入队，立即返回排队中（类似 12306 的买票时的排队）
4.请求出队，生成订单，减少库存
5.客户端轮询，是否秒杀成功

### MQ怎么做消息的高可用

最大限度做到消息的不丢失，尽可能的被下游消费到

## 文章投票

构建一个文章投票网站，我们首先要做的就是为了这个网站设置一些数值和限制条件:

- 如果一篇文章获得了至少200 张支持票 (up vote)那么网站就认为这篇文章是一篇有趣的文章;
- 假如这个网站每天发布 1000 篇文章，而其中的50篇符合网站对有趣文章的要求，那么网站要做的就是把这 50篇文章放到文章列表前 100 位至少一天;
- 另外，这个网站暂时不提供投反对票(downvote)的功能。

为了产生一个能够随着时间流逝而不断减少的评分，程序需要根据文章的发布时间和当前时间来计算文章的评分，具体的计算方法为：将文章得到的支持票数量乘以一个常量，然后加上文章的发布时间，得出的结果就是文章的评分。

计算评分时与支持票数量相乘的常量为 432，这个常量是通过将一天的秒数(86 400)除以文章展示一天所需的支持票数量(200)得出的：文章每获得一张支持票，程序就需要将文章的评分增加432 分。

使用hash进行存储

```sh
key:article:articleId
val:title、link、poster、time、votes
```

为了防止用户对同一篇文章进行多次投票，网站需要为每篇文章记录一个已投票用户名单，为此，程序将为每篇文章创建一个集合，并使用这个集合来存储所有已投票用户的 Id

set存储每篇投票的用户Id

```java
key:article:vote:articleId
val:userId
```

为了尽量节约内存，我们规定当一篇文章发布期满一周之后，用户将不能再对它进行投票，文章的评分将被固定下来，而记录文章已投票用户名单的集合也会被删除。



## 登录与Cookie缓存

每当我们登录互联网服务(比如银行账户或者电子邮件)的时候，这些服务都会使用cookie 来记录我们的身份。cookie 由少量数据组成，网站会要求我们的浏览器存储这些数据并在每次服务发送请求时将这些数据传回给服务。对于用来登录的 cookie，有两种常见的方法可以将登录信息存储在 cookie 里面：一种是签名(signed)cookie，另一种是令牌 (token)cookie。

- **签名 cookie** 通常会存储用户名，可能还有用户ID、用户最后一次成功登录的时间，以及网站觉得有用的其他任何信息。除了用户的相关信息之外，签名 cookie 还包含一个签名，服务器可以使用这个签名来验证浏览器发送的信息是否未经改动(比如将 cookie 中的登录用户名改成另一个用户)。
  - 优点：验证cookie所需的一切信息都存储在 cookie里面。cookie可以包含额外的信息(additionalinfomation)，并且对这些信息进行签名也很容易。
  - 缺点：正确地处理签名很难。很容易忘记对数据进行签名，或者忘记验证数据的签名，从而造成安全漏洞
- **令牌 cookie** 会在 cookie 里面存储一串随机字节作为令牌，服务器可以根据令牌在数据库中查找令牌的拥有者。随着时间的推移，旧令牌会被新令牌取代。
  - 优点：添加信息非常容易。cookie 的体积非常小，因此移动终端和速度较慢的客户端可以更快地发送请求；
  - 缺点：需要在服务器中存储更多信息。如果使用的是关系数据库，那么载入和存储 cookie的代价可能会很高。



## 用户和状态

用户对象存储了用户的基本身份标识信息、用户的关注者人数、用户已发布的状态消息数量等信息。

Hash存储用户信息：

```java
key:user:userId
//-------------------------------
login   //
id      //userId?
name		//用户名
follers    //用户拥有的关注者人数
following  //用户正在关注的人的数量
posts      //发帖数
signup		//登录时间
```

登录验证

```java
1.校验提交过来的手机号，是否符合；如果不符合直接返回错误信息；
2.从redis中获取验证码，校验用户的验证码；如果不一致，直接返回错误信息；
3.验证码校验成功，从mysql中查询用户信息，校验用户是否存在；
4.如果用户不存在，创建新的用户并保存；如果存在校验账号信息不存在，返回错误信息
5.将用户信息保存在redis中
5.1生产随机token,作为登入令牌
5.2将User对象转为HashMap存储
5.3存入redis中
5.4设置key有效时间

```

发送验证码

```java
1.校验手机号；如果不符合，直接返回错误信息；
2.生成验证码；
3.保存验证码到redis中，并设置有效时间为2分钟；
4.发送验证码；
5.返回结果；
```

用户签到

```java
1.获取当前用户，当前日期；
2.拼接key，key = USER_SIGN_KEY + userId + 时间戳;
3.计算今天是当前月的第几天，dayOfMonth；
4.获取本月所有签到记录，返回十进制数字record，如果没有返回0；
5.将1左移dayOfMonth后，和签到记录record作与运算；
6.计算二进制中1的个数，记为连续签到天数。
```

## 用户关注

redis中用户关注集合使用set集合，因为只需要存储用户的Id，并且没有顺序。

用户关注Redis结构(set集合)：

```java
key: follow:userId
val: userId
```

用户关注

```java
1. 获取当前登录用户；
2. 创建关注用户的redis key，follow：userId
3. 从redis中查询当前用户的关注集合；
4. 如果存在followUserId，证明是取消关注，则将followUserId从reids和mysql中删除；
5. 如果不存在，表示是关注，则将followUserId加入到redis和mysql中；
```



项目

- Echo 的注册功能是怎么做的

- Echo 的登录认证和授权是怎么做的

- Echo 的发帖操作是怎么做的

- 帖子列表与分页是怎么做的

  帖子列表显示标题、发布时间、用户信息、前2行内容（前多少内容）

- 帖子详情

  根据帖子的Id查询帖子详情（帖子的类容，发帖人信息，帖子的点赞、评论）

  1. 先根据帖子Id查询帖子信息，其中包括了用户的id
  2. 根据用户Id再查询用户信息

- 帖子评论是如何显示的
  评论的目标是可以针对很多中类型，如，帖子、课程、话题

      1. 多级评论结果是一种树形结构，通过在表中`主键id`和`pid字段`实现树形结构的存储，pid默认为0表示一级评论，pid不为0表示对某个评论的回复；
      2. 评论人信息根据`user_id`实现查询，主要是为了避免用户信息更改，造成评论信息不一致问题；
      3. 对于点赞信息根据`like_id`实现查询

  Redis缓存评论，不缓存评论的回复，根据点赞数排行。

  key设计`comments:postId-commentid` 。

  ​

  数据库设计，评论结构是一种树形结构显示

  ```Java
  CREATE TABLE `comments_info` (
    `comment_id` varchar(32) NOT NULL COMMENT '主键id',
    `target_id` varchar(32) NOT NULL COMMENT '帖子id',
    `type` tinyint(1) NOT NULL COMMENT '评论类型：对人评论，对项目评论，对资源评论',
    `pid` varchar(32) DEFAULT '0' NOT NULL COMMENT '父评论的主键Id，默认为0，表示对帖子的评论',
    `to_id` varchar(32) NOT NULL COMMENT '被评论者id，可以是人、项目、资源',
    `from_id` varchar(32) NOT NULL COMMENT '评论者id',
    `like_id` int(11) DEFAULT '0' COMMENT '点赞的数量',
    `content` varchar(512) DEFAULT NULL COMMENT '评论内容',
    `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
    PRIMARY KEY (`id`),
    KEY `comment_id` (`comment_id`)
  ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='评论表';
  ```






- 帖子列表

  帖子列表是一页显示10条信息（用户名、用户头像、用户等级、评论内容、点赞），只显示用户的一级评论信息，如果要查看评论的回复，需要再进行查询

- 点赞功能

  需求：

  1. 同一个用户只能点赞一次，在此点赞则取消；
  2. 如果但钱用户已经点赞，则点赞按钮表示已经点赞。

  实现方案：

  1. 给帖子添加isLike字段，表示是否被当前用户点赞；
  2. 修改该点赞功能，利用redis的set集合判断是否被点赞过，未点则加1，已点则减一；
  3. 修改根据Id查询Blog业务，判断当前登录用户是否被点赞过；
  4. 修改分页查询Blog业务，判断当前登录用户是否点赞过

  redis中点赞key设计：key为`post：liked：id`，value为用户id

  点赞`redisTemplate,opsForZSet().add(key,userId.toString(), s,System.currentTimeMillis())`

  查询是否点赞时`score = RedisTemplate.opsForZset().score(key,value)`



## 关注页-文章

「关注页」，关注页的逻辑十分常见就是将用户关注的创作者发表的文章聚合在一起，按时间倒序排列即可。

Feed 流产品一般有两种形态：

- 一种是基于算法推荐
- 一种是基于关注关系并按时间排列。

「关注页」这种按时间排序的 Feed 流也被为 Timeline。「关注页」自然的也被称为「关注 Timeline」, 存放自己发送过的 Feed 的页面被称为「个人 Timeline」 比如微博的个人页。

### 拉模式

在查询时首先查询用户关注的所有创作者 uid，然后查询他们发布的所有文章，最后按照发布时间降序排列。

![输入图片说明](https://foruda.gitee.com/images/1684673418435212361/9adbf814_8616658.png "屏幕截图")

使用拉模型方案用户每打开一次「关注页」系统就需要读取 N 个人的文章（N 为用户关注的作者数）, 因此拉模型也被称为读扩散。

拉模型不需要存储额外的数据，而且实现比较简单：发布文章时只需要写入一条 articles 记录，用户关注(或取消关注)也只需要增删一条 followings 记录。特别是当粉丝数特别多的头部作者发布内容时不需要进行特殊处理，等到读者进入关注页时再计算就行了。

拉模型的问题同样也非常明显，每次阅读「关注页」都需要进行大量读取和一次重新排序操作，若用户关注的人数比较多一次拉取的耗时会长到难以接受的地步。

### 推模式

在创作者发布文章时就应该将新文章写入到粉丝的关注 Timeline，用户每次阅读只需要到自己的关注 Timeline 拉取就可以了。

![输入图片说明](https://foruda.gitee.com/images/1684673223535401841/1ff62a35_8616658.png "屏幕截图")

使用推模型方案创作者每次发布新文章系统就需要写入 M 条数据（M 为创作者的粉丝数），因此推模型也被称为写扩散。推模型的好处在于拉取操作简单高效，但是缺点一样非常突出。

首先，在每篇文章要写入 M 条数据，在如此恐怖的放大倍率下关注 Timeline 的总体数据量将达到一个惊人数字。而粉丝数有几十万甚至上百万的头部创作者每次发布文章时巨大的写入量都会导致服务器地震。

通常为了发布者的体验文章成功写入就向前端返回成功，然后通过消息队列异步地向粉丝的关注 Timeline 推送文章。

![输入图片说明](https://foruda.gitee.com/images/1684673386672916620/9316da60_8616658.png "屏幕截图")

通常为了发布者的体验文章成功写入就向前端返回成功，然后通过消息队列异步地向粉丝的关注 Timeline 推送文章。

### 在线推，离线拉

粉丝群体中活跃用户是有限的，我们完全可以只推送给活跃粉丝，不给那些已经几个月没有启动 App 的用户推送新文章。

至于不活跃的用户，在他们回归后使用拉模型重新构建一下关注 Timeline 就好了。因为不活跃用户回归是一个频率很低的事件，我们有充足的计算资源使用拉模型进行计算。

![输入图片说明](https://foruda.gitee.com/images/1684673039393041984/ccd6f98b_8616658.png "屏幕截图")

因为活跃用户和不活跃用户常常被叫做「在线用户」和「离线用户」，所以这种通过推拉结合处理头部作者发布内容的方式也被称为「在线推，离线拉」。

### 加入Redis

不管是「关注 Timeline」还是关注关系等数据我们都存储在了 MySQL 中。

关注 Timeline 与缓存一样只需要**暂时**存储**热门数据**，给关注 Timeline 存储设置过期时间，若用户一段时间没有打开 App 他的关注 Timeline 存储将被过期释放，在他回归之后通过拉模型重建即可。

在使用「在线推，离线拉」策略时我们需要判断用户是否在线，在为 Timeline 设置了过期时间后，Timeline 缓存是否存在本身即可以作为用户是否在线的标志。

用户总是关心关注页中最新的内容，所以关注 Timeline 中也没有必要存储完整的数据只需要存储最近一段时间即可，旧数据等用户翻阅时再构建就行了。

Redis 中有序数据结构有列表 List 和有序集合 SortedSet 两种，对于关注 Timeline 这种需要按**时间排列**且**禁止重复**的场景当然闭着眼睛选 SortedSet。

将 article_id 作为有序集合的 member、发布时间戳作为 score, 关注 Timeline 以及个人 Timeline 都可以缓存起来。

在推送新 Feed 的时候只需要对目标 Timeline 的 SortedSet 进行 ZAdd 操作。若缓存中没有某个 Timeline 的数据就使用拉模型进行重建。

在使用消息队列进行推送时经常出现由于网络延迟等原因导致重复推送的情况，所幸 article_id 是唯一的，即使出现了重复推送 Timeline 中也不会出现重复内容。

对于时间线这种集合式的还存在第二类缓存穿透问题，正如我们刚刚提到的 Redis 中通常只存储最近一段时间的 Timeline，当我们读完了 Redis 中的数据之后无法判断数据库中是否还有更旧的数据。

这两类问题的解决方案是一样的，我们可以在 SortedSet 中放一个 `NoMore` 的标志，表示数据库中没有更多数据了。对于 Timeline 本来为空的用户来说，他们的 SortedSet 中只有一个 NoMore标志。

最后一点：拉取操作要注意保持原子性不要将重建了一半的 Timeline 暴露出去。先合并完然后用一个ZAdd命令推送到关注页Timeline。

总结一下使用 Redis 做关注时间线的要点:

- 使用 SortedSet 结构存储，Member 为 FeedID，Score 为时间戳
- 给缓存设置自动过期时间，不活跃用户的缓存会自动被清除。使用「在线推，离线拉」时只给 Timeline 缓存未失效的用户推送即可
- 需要在缓存中放置标志来防止缓存击穿

**分页器**

Feed 流是一个动态的列表，列表内容会随着时间不断变化。传统的 limit + offset 分页器会有一些问题：

![输入图片说明](https://foruda.gitee.com/images/1684672565808547406/7e8cf698_8616658.png "屏幕截图")

在 T1 时刻读取了第一页文章id[1，2，3，4，5]，T2时刻有人新发表了 article 11 ，如果这时来拉取第二页，会导致 article 6 在第一页和第二页都被返回了。

解决这个问题的方法是根据上一页最后一条 Feed 的 ID 来拉取下一页：

![输入图片说明](https://foruda.gitee.com/images/1684672599173974783/9f311912_8616658.png "屏幕截图")

使用 Feed ID 来分页需要先根据 ID 查找 Feed，然后再根据 Feed 的发布时间读取下一页，流程比较麻烦。若作为分页游标的 Feed 被删除了，就更麻烦了。

使用时间戳来作为游标：

![输入图片说明](https://foruda.gitee.com/images/1684672704140312270/0edf0392_8616658.png "屏幕截图")

使用时间戳不可避免的会出现两条 Feed 时间戳相同的问题, 这会让我们的分页器不知所措。

![输入图片说明](https://foruda.gitee.com/images/1684672758544037035/bffb02a9_8616658.png "屏幕截图")

有个小技巧是将 Feed id 作为 score 的小数部分，比如 article 11 在 2022-10-27 13:55:11 发布（时间戳 1666850112）， 那么它的 score 为 1666850112.11 小数部分既不影响按时间排序又避免了重复。

![输入图片说明](https://foruda.gitee.com/images/1684672787983469679/b8624d94_8616658.png "屏幕截图")

**大规模推送**

虽然我们已经将推送 Feed 的任务转移给了 MQ Worker 来处理，但面对将 Feed 推送给上百万粉丝这样庞大的任务, 单机的 Worker 还是很难处理。 而且一旦处理中途崩溃就需要全部重新开始。

我们可以将大型推送任务拆分成多个子任务，通过消息队列发送到多台 MQ Worker 上进行处理。

![输入图片说明](https://foruda.gitee.com/images/1684672960835261451/b5791d39_8616658.png "屏幕截图")

因为负责拆分任务的 Dispatcher 只需要扫描粉丝列表负担和故障概率大大减轻。若某个推送子任务失败 MQ 会自动进行重试，也无需我们担心。

来自 https://www.cnblogs.com/Finley/p/16857008.html



## 抽奖系统

一个满足业务需求的抽奖系统，需要提供抽奖活动配置、奖品概率配置、奖品梳理配置等内容，同时用户在抽奖后需要记录用户的抽奖数据，这就是一个抽奖活动系统的基本诉求。

### 整体流程

#### 根据用户信息进行抽奖

1. 根据用户信息量化抽奖人群（`用户信息：用户ID、规则树Id、决策值`）

   1. 执行规则引擎，获取用户可以参与的活动号

      1. 量化决策，获取决策结果（`决策结果：执行结果状态、用户Id、规则树Id、果实节点Id、果实节点值即活动Id`）

   2. 执行抽奖

      1. 领取活动（参与活动）

         1. 查询是否存在未执行抽奖领取活动单【user_take_activity 存在 state = 0，领取了但抽奖过程失败的，可以直接返回领取结果继续抽奖】

            根据活动Id和用户Id，从mysql中查询用户活动信息，如果存在一条信息且state的状态为0，表示用户参与了活动但是抽奖过程失败了

            得到结果：`用户领取活动记录：活动Id、活动领取Id、策略Id`

         2. 查询活动账单

            参数：用户Id、活动Id、活动领取时间

            结果：活动账单

            流程：

            1. 根据活动Id在mysql中查询活动基础信息（自增Id、活动Id、活动名称、活动描述、开始时间、结束时间、库存、库存剩余、没人可参与次数、策略Id、活动状态、创建人、创建时间、修改时间）
            2. 从redis缓存中获取库存，库存信息
            3. 根据用户Id和活动Id查询用户参与活动次数，用户活动参与次数信息（自增Id、用户Id、活动Id、可参与次数、已经参数次数）
            4. 封装活动账单（用户Id、活动Id、活动名称、开始时间、结束时间、库存、剩余库存、活动状态、策略Id、每人可参与的次数、已经参与的次数）

         3. 活动信息校验处理(活动库存、状态、日期、个人参与次数)

            参数：PartakeReq（用户Id、活动Id、活动参与时间），活动账单ActivityBillVO

            结果：校验是否成功

            流程：

            1. 校验活动状态
            2. 校验活动日期
            3. 校验活动库存
            4. 校验个人库存 - 个人活动剩余可领取次数

         4. 扣减活动库存，通过Redis（活动库存扣减编号，作为key，缩小粒度）begin

            参数：用户Id、活动Id、库存数stockCount

            结果：库存处理结果StockResult（库存key、活动库存剩余）

            流程：

            1. 获取抽奖活动库存key
            2. 使用redis的incr扣减库存，返回当前库存数
            3. 剩余库存超出了库存stockCount，则使用redis的decr恢复原始库存
            4. 以活动库存占用编号，生产对加锁key，细化锁颗粒度`lottery_activity_stock_count_token_活动Id-stockUsedCount`
            5. 使用redis.setNx加一个分布式锁
            6. 返回结果

         5. 插入领取活动信息（个人用户把活动信息写入到用户表）

            参数：PartakeReq , ActivityBillVO , takeId

            结果：是否操作成功

            流程：

            1. mysql中UserTakeActivity表扣减个人参与次数
            2. mysql中UserTakeActivity写入用户领取活动记录

         6. 扣减库存结束，恢复活动库存，通过Redis（如果非常异常，则需要进行缓存库存恢复，只保证不超卖的特性，所以不保证一定能回复占用库存，另外最终可以由任务进行补偿库存）

            参数：activityId, tokenKey, code

            结果：void

            流程：删除分布式锁 key

         7. 返回结果PartakeResult：策略Id、活动领取Id、库存、剩余库存

      2. 首次成功领取活动，发送MQ消息

         参数：ActivityPartakeRecordVO（用户Id、活动Id、库存、剩余库存）

         结果：void

         流程：mq发送消息

      3. 执行抽奖

         参数：

         结果：

         流程：模板方法模式定义抽奖过程

         1. 获取抽奖策略

            参数：策略Id：strategyId

            结果：StrategyRich：策略Id、策略配置StrategyBriefVO、策略明细List<StrategyDetailBriefVO>

            流程：

            1. 从Strategy数据表中根据策略Id查询策略信息Strategy
            2. 从策略详细表StrategyDetail中根据策略id查询策略表详细配置List<StrategyDetail>
            3. 根据查询到的策略Strategy和策略表详细配置List<StrategyDetail>封装返回结果Strategy。

         2. 校验抽奖策略是否已经初始化到内存

            参数：抽奖策略Id strategyId, 抽奖模式 strategyMode, 抽奖详情List<StrategyDetailBriefVO> 

            结果：void

            流程：

            1. 解析并初始化中奖概率数据到散列表
            2. 根据算法为每个奖品配置中奖概率

         3. 获取不在凑将范围内的列表，包括奖品库存为空、风控策略、临时调整等，这类数据含有业务逻辑的，所以需要由具体的实现方法决定

            参数：策略Id：strategyId

            结果：排除的奖品Id集合：List<String>

            流程：从StrategyDetail表中根据策略Id查询无库存策略奖品Id合集

         4. 执行抽奖算法

            参数：策略Id-strategyId，抽奖算法模型-IDrawAlgorithm，排除的抽奖Id集合

            结果：中奖Id

            流程：

            1. 执行抽奖

               参数：策略Id-strategyId，排除已经不能作为抽奖的奖品Id，留给风控的空库存使用-excludeAwardIds

               结果：中奖结果Id

               流程：使用算法选出中奖结果Id

            2. 判断抽奖结果

            3. 扣减库存，暂时采用数据库行级锁的方式进行扣减库存，后续优化为Redis分布式锁扣减 decr/incr

            4. 返回结果，库存扣减成功返回奖品Id，否则返回NUll（在实际的业务场景中，如过中将奖品库存为空，则会发送兜底奖品，比如各类券）

         5. 包装中将结果

            参数：用户Id-uId；策略Id-strategyId；奖品Id，null情况：并发抽奖情况下，库存临界值1->0,会有用户中将结果为null；策略简要信息-StrategyBriefVO（策略Id、策略描述、策略方式、发放奖品方式、发放奖品时间、扩展信息）

            结果：抽奖结果-DrawResult（用户Id、策略Id、中奖状态、中奖奖品信息）

            流程：

            1. 查询奖品详情信息

               参数：奖品Id-awardId

               结果：Award信息（自增Id、奖品Id、奖品类型、奖品数量、奖品名称、奖品内容、）

               流程：根据奖品Id从Award表中查询奖品信息

            2. 封装奖品信息，返回抽奖结果DrawResult

            ​

      4. 结果落库

         参数：

         结果：是否成功Result

         流程：

         1. 转换数据DrawResult->DrawOrderVO

         2. 保存奖品单

            参数：奖品单-DrawOrderVO

            结果：是否成功Result

            流程：

            1. 锁定活动领取记录

               参数：用户Id-uId；活动Id-activityId；领取Id-takedId

               结果：更新结果-int

               流程：从UserTakeActivity表锁定活动领取记录

            2. 保存抽奖信息

               参数：中奖单-DrawOrderVO

               结果：

               流程：在UserStrategy表中插入一条新的中将单信息

               ​

      5. 发送MQ，触发发奖流程

         流程：

         1. 将奖品单DrawOrderVO转换为中奖物品发送单InvoiceVO，用于发送MQ消息，异步出发发货奖品给用户

         2. mq发送中奖物品发送单-InvoiceVO消息

         3. 对MQ消息结果处理

            流程：

            1. MQ消息发送完成，更新数据库表 user_strategy_export.mq_state = 1 ，更新UserStrategyExport数据库表的MQ发送Mq状态

            2. MQ 消息发送失败，更新数据库表 user_strategy_export.mq_state = 2 【等待定时任务扫码补偿MQ消息】

      6. 返回结果

         流程：将活动抽奖结果DrawAwardVO封装到Result返回

   3. 数据转换

      流程：将抽奖结果DrawAwardVO转换为奖品信息AwardDTO

   4. 抽奖完成，数据转换

      流程：将抽奖结果AwardDTO转换为抽奖结果DrawRes

### 模板模式设计抽奖流程

模板方法模式使用场景：当要完成某个过程，该过程要执行一系列步骤，这一系列的步骤基本相同，但其个别步骤在是实现可能不同，通常考虑模板方法模式来处理。

### 抽奖策略

**需求**：在一场营销抽奖活动玩法中，运营人员通常会配置以转盘、盲盒等展现形式的抽奖玩法。例如在转盘中配置12个奖品，每个奖品配置不同的中奖概率，当1个奖品被抽空了以后，那么再抽奖时，是剩余的奖品总概率均匀分配在11个奖品上，还是保持剩余11个奖品的中奖概率，如果抽到为空的奖品则表示未中奖。其实这两种方式在实际的运营过程中都会有所选取，主要是为了配合不同的玩法。

## 规则引擎

基于量化决策引擎，筛选用户身份标签，找到符合参与的活动号。拿到活动号后，就可以参与到具体的抽奖活动中了。

通常量化决策引擎也是一种用于差异化人群的规则过滤器，不只是可以过滤出活动，也可以用于活动唯独的过滤，判断是否可以参与到这个抽奖活动中。

在我们的这个抽奖系统后，后面会使用规则引擎领域服务，在应用层做一层封装后，由接口层进行调用使用。*也就是用户参与活动之前，要做一层规则引擎过滤



- Echo 的发布评论是怎么做的

- Echo 的私信列表与详情页是怎么做的

- Echo 的发送私信是怎么做的

- Echo 的点赞模块是怎么做的

- Echo 的关注模块是怎么做的

- Echo 的系统通知模块是怎么做的

- Echo 的置顶、加精、删除帖子是怎么做的

- Echo 是如何统计网站数据的

- Echo 的搜索模块是怎么做的

- Echo 是如何支持 MarkDown 的

- redis分页怎么做的

  ​