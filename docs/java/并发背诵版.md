## 1. 线程

### 1.1 线程和进程的区别

- 进程是**操作系统资源分配**的基本单位，二线程是**处理器任务调度**的基本单位
- 进程是正在运行程序的实例，进程中包含了线程，每个线程执行不同的任务
- 不同的进程使用不同的内存空间，在同一进程下的所有线程可以共享内存空间
- 线程更轻量，每个线程都有自己独立的运行栈和程序计数器，线程上下文切换成本一般上要比进程上下文切换开销更小

### 1.2 并行和并发的区别

操作系统中的任务调度器，将cpu的时间片（windows下时间片最小约为 15 毫秒）分给不同的程序使用，只是由于cpu在线程间（时间片很短）的切换非常快，感觉是同时运行的 ，因此在微观串行，宏观并行，这种线程轮流使用CPU的做法称为并发。

在多核cpu下，可以将多核分配给不同的线程同时运行，微观上是并行的。

### 1.3 创建线程的 3 种方式

1. 实现Runnable接口
2. 实现Callable接口，需要指定一个泛型，这个泛型就是返回值的类型，重写call方法，还需要配合FutureTask使用，将FutureTask交给Thread类，通过Thread类的start方法启动线程
3. 继承Thread类，重写run方法
4. 线程池

实现 Runnable 和 Callable 接口的类**只能当做一个可以在线程中运行的任务**，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说**任务是通过线程驱动从而执行的**。

#### 1.3.1 Runnable 和 Callable接口的区别

- Runnable 接口run方法没有返回值；Callable接口call方法有返回值，是个泛型，和Future、FutureTask配合可以用来获取异步执行的结果
- Callalbe接口支持返回执行结果，需要调用**FutureTask.get()得到，此方法会阻塞主进程的继续往下执行**，如果不调用不会阻塞
- Callable接口的call()方法允许抛出异常；而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛

#### 1.3.2 线程的 run()和 start()有什么区别

- start(): 用来启动线程，通过该线程调用run方法执行run方法中所定义的逻辑代码。start方法只能被调用一次。
- run(): 封装了要被线程执行的代码，可以被调用多次。

### 1.4 线程状态

线程状态有：new、Runnable、Waiting、Timed Waiting、Blocked、Terminated。

#### 1.4.1 线程状态转换

![输入图片说明](https://foruda.gitee.com/images/1691914796910698798/25546453_8616658.png "线程状态转换")

- New：线程创建了，但还没有执行start方法，此时未与操作系统底层线程关联

- Runnable：可运行状态，调用start方法线程状态会从New状态转变为Runnable状态，此时与底层线程关联，由操作系统调度执行；于可运行状态的线程正在 Java 虚拟机中执行，但它可能正在等待资源（来自操作系统的其他资源，例如处理器）

- Blocked：线程阻塞等待监视器锁的线程状态

  当可运行状态的线程，当获取锁失败后，由可运行进入 Monitor 的阻塞队列阻塞，此时不占用cpu 时间；当持锁线程释放锁时，会按照一定规则唤醒阻塞队列中的阻塞线程，唤醒后的线程进入可运行状态

- Wating：处于等待状态的线程正在等待另一个线程执行特定操作

  Runnable状态的线程，当获取锁成功后，但由于条件不满足，调用了 wait() 方法，此时从Runnable状态**释放锁进入 Monitor 等待集合等待**，同样不占用 cpu 时间；当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的等待线程，恢复为可运行状态

- Timed Waiting：具有指定等待时间的等待线程的线程状态

  - 当获取锁成功后，但由于条件不满足，调用了 **wait(long)** 方法，此时从可运行状态**释放锁进入 Monitor 等待集合**进行有时限等待，同样不占用 cpu时间；当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的有时限等待线程，恢复为可运行状态，并重新去竞争锁
  - 如果等待超时，也会从有时限等待状态恢复为可运行状态，并重新去竞争锁
  - 还有一种情况是调用 **sleep(long)** 方法也会从可运行状态进入有时限等待状态，但**与 Monitor 无关**，**不会释放锁，但是会释放CPU资源**，不需要主动唤醒，超时时间到自然恢复为可运行状态

- Terminated：已终止线程的线程状态

#### 1.4.2 join方法

join方法在当前线程中`t1.join()`，表示当前线程等待t1线程执行完后被等待唤醒。

join方法相当于：

```java
 while (t1.isAlive()) {
   obj.wait(0);
}
```



#### 1.4.3 wait 和sleep

wait 和 sleep 方法都会使得线程**放弃CPU资源进入Waiting状态**。

wait 方法是对象Object的方法，sleep 方法是Thread的静态方法。

wait 方法会释放锁，进入锁对象的等待集合，等待被唤醒；而**sleep 方法则与 Monitor 无关，不会释放锁，会释放CPU资源**，不需要主动唤醒，超时时间到自然恢复为可运行状态。

wait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制

#### 1.4.4 notify 和 notifyAll

notifyAll：唤醒所有wait的线程，进行锁的竞争
notify：只随机唤醒一个 wait 线程



#### 1.4.5 如何停止一个线程

- 使用退出标志，使线程正常退出，也就是当run方法完成后线程终止
- 使用stop方法强行终止（不推荐，方法已作废）
- 使用interrupt方法中断线程

> stop强行终止线程会出现什么问题？

## 2 线程并发锁

### 2.1 synchronized

Synchronized**对象锁**采用互斥的方式让**同一时刻至多只有一个线程能持有对象锁**，其它线程再想获取这个对象锁时就会阻塞住

#### 2.1.1 synchronized基本实现

从字节码层面看：

它的底层由monitor实现的，monitor是jvm级别的对象（ C++实现），线程获得锁需要使用对象（锁）关联monitor；JVM保证一个monitor一次只能被一个线程占有。其中，monitorenter和monitorexit是两个与监视器相关的字节码指令。

- 当线程执行monitorenter的时候尝试获取栈顶对象的监视器monitor，也就是尝试获取锁，如果此时monitor没有被其他线程占用就获得锁，monitor计数器设置为1，当线程已经获得monitor的所有权了，monitorenter指令也会顺利执行，monitor计数器+1.如果其他线程拥有monitor的所有权，当前线程会阻塞，直到monitor计数器变为0。
- 当线程执行monitorexit指令的时候，监视器计数器-1，计数器为0的时候锁被释放，其他等待的线程可以尝试获得monitor的所有权.

#### 2.1.2 Monitor

Monitor内部具体的存储结构：

- Owner：存储当前获取锁的线程的，只能有一个线程可以获取
- EntryList：关联没有抢到锁的线程，处于Blocked状态的线程
- WaitSet：关联调用了wait方法的线程，处于Waiting状态的线程

具体的流程：

- 代码进入synchorized代码块，先让lock（对象锁）关联的monitor，然后判断Owner是否有线程持有
- 如果没有线程持有，则让当前线程持有，表示该线程获取锁成功
- 如果有线程持有，则让当前线程进入entryList进行阻塞，如果Owner持有的线程已经释放了锁，在EntryList中的线程去竞争锁的持有权（非公平）
- 如果代码块中调用了wait()方法，则会进去WaitSet中进行等待



#### 2.1.3 Monitor为什么是重量级锁

Monitor实现的锁属于重量级锁，里面涉及到了用户态和内核态的切换、进程的上下文切换，成本较高，性能比较低

当Monitor的Owner为null，唤醒EntryList中的线程进行锁竞争是依赖底层操作系统进行的，会让每一个线程都切换到内核态，由内核协调哪个线程获取到锁，哪些线程无法获取到锁。获取锁成功的线程会被唤醒，获取锁失败的线程会被内核进行阻塞，线程阻塞才能释放CPU资源，执行完才会从内核态转换为用户态。



#### 2.1.4锁升级过程

**偏向锁：**一段很长的时间内都只被一个线程使用锁，可以使用了偏向锁，在第一次获得锁时，会有一个CAS操作，之后该线程再获取锁，只需要判断mark word中是否是自己的线程id即可，而不是开销相对较大的CAS命令

**轻量级锁：**线程加锁的时间是错开的（也就是没有竞争），可以使用轻量级锁来优化。轻量级修改了对象头的锁标志，相对重量级锁性能提升很多。每次修改都是CAS操作，保证原子性

**重量级锁：**底层使用的Monitor实现，里面涉及到了用户态和内核态的切换、进程的上下文切换，成本较高，性能比较低。

**一旦锁发生了竞争，都会升级为重量级锁**

在HotSpot虚拟机中，对象在内存中存储的布局可分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充；其中对象头包括了Mark Word 和 class Word

其中Mark Word记录了获取锁的线程Id、锁状态、年龄等信息。

**偏向锁：**当锁对象第一次被一个线程获得，即偏向锁

只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现这个线程 ID 是自己的就表示没有竞争，不用重新 CAS

**轻量级锁：**一个对象有多个线程要加锁，但加锁的时间是错开的（没有竞争），可以使用轻量级锁来优化，轻量级锁对使用者是透明的（不可见）

- 在线程栈中创建一个Lock Record，将其Object Reference字段指向锁对象
- 通过CAS指令将Lock Record的线程id存储在锁对象的对象头的mark word中，同时也设置偏向锁的标识为101，如果对象处于无锁状态则修改成功，代表该线程获得了偏向锁。
- 如果是当前线程已经持有该锁了，代表这是一次锁重入。设置Lock Record第一部分为null，起到了一个重入计数器的作用。与轻量级锁不同的时，这里不会再次进行cas操作，只是判断对象头中的线程id是否是自己，因为缺少了cas操作，性能相对轻量级锁更好一些

**重量级锁：**

在尝试加轻量级锁的过程中，CAS 操作无法成功，可能是其它线程为此对象加上了轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁变为**重量级锁**

* 当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁
* Thread-1 加轻量级锁失败，进入锁膨胀流程：为 Object 对象申请 Monitor 锁，**通过 Object 对象头获取到持锁线程**，将 Monitor 的 Owner 置为 Thread-0，将 Object 的对象头指向重量级锁地址，然后自己进入 Monitor 的 EntryList BLOCKED
* 当 Thread-0 退出同步块解锁时，使用 CAS 将 Mark Word 的值恢复给对象头失败，这时进入重量级解锁流程，即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中 BLOCKED 线程

### 1.3 基础线程机制（线程池，守护线程，sleep()，yield()）

**Daemon**
**守护线程**是程序运行时在后台提供服务的线程。
**当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程**（与普通线程的最大区别，普通线程要手动控制结束）。

使用 `setDaemon()` 方法将一个线程设置为守护线程

## 3 线程池

### 3.1 什么是线程池？

线程池：一个容纳多个线程的容器，容器中的线程可以重复使用，省去了频繁创建和销毁线程对象的操作。

线程池的核心思想：**线程复用**，同一个线程可以被重复使用，来处理多个任务

池化技术 (Pool) ：一种编程技巧，核心思想是资源复用，在请求量大时能优化应用性能，降低系统频繁建连的资源开销。



### 3.2 使用线程池好处？

1. **降低资源消耗**，通过重复利用已创建的线程**降低线程创建和销毁造成的消耗**。
2. **提高响应速度**，当任务到达时，如果有线程可以直接用，不需要等待线程的创建就可以立即执行。
3. **提高线程的可管理性**，线程是稀缺资源，如果无限制的创建线程，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控

### 3.3 线程池核心参数



### 3.4 线程池阻塞队列

1. ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO。

   底层是数组，初始化时需要指定的队列容量；只有一把锁，读和写公用，性能相对于LinkedBlockingQueue差一些

   > ArrayBlockingQueue只有一把锁，是排他锁吗？为什么？

2. LinkedBlockingQueue：基于链表结构的有界阻塞队列，FIFO。

   底层是单项链表，默认无界，支持有界，创建节点的时候添加数据（是懒惰的），头尾有两把锁，即读写各一把锁

3. DelayedWorkQueue ：是一个优先级队列，它可以保证每次出队的任务都是当前队列中执行时间最靠前的

   > 底层是什么结构？

4. SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作。

### 3.5 线程池的执行流程

1. 创建线程池，这时没有创建线程（**懒惰**），等待提交过来的任务请求，调用 execute 方法才会创建线程
2. 当调用 execute() 方法添加一个请求任务时，线程池会做如下判断：
   - 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务
   - 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列
   - 如果这时队列满了且正在运行的线程数量还小于 maximumPoolSize，那么会创建非核心线程**立刻运行这个任务**，对于阻塞队列中的任务不公平。这是因为创建每个 Worker（线程）对象会绑定一个初始任务，启动 Worker 时会优先执行
   - 如果队列满了且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会启动饱和**拒绝策略**来执行
3. 当一个线程完成任务时，会从队列中取下一个任务来执行
4. 当一个线程空闲超过一定的时间（keepAliveTime）时，线程池会判断：如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉，所以线程池的所有任务完成后最终会收缩到 corePoolSize 大小

> 当有任务提交，线程池中的线程是先执行队列中的任务还是从队列中获取一个线程执行？

### 3.6 线程池大小的确定

- **CPU 密集型任务(N+1)**： 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。
- **I/O 密集型任务(2N)**： 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

### 3.7 线程池种类

在java.util.concurrent.Executors类中提供了大量创建连接池的静态方法，常见就有四种

1. newFixedThreadPool：创建一个拥有固定数量线程的线程池

   ```java
   public static ExecutorService newFixedThreadPool(int nThreads) {
       return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS,
                                     new LinkedBlockingQueue<Runnable>());
   }
   ```

   - 核心线程数 == 最大线程数（没有救急线程被创建），因此也无需超时时间
   - LinkedBlockingQueue 是一个单向链表实现的阻塞队列，默认大小为 `Integer.MAX_VALUE`，也就是无界队列，可以放任意数量的任务，在任务比较多的时候会导致 OOM（内存溢出）
   - 适用于任务量已知，相对耗时的长期任务


2. newSingleThreadExecutor：创建一个只有 1 个线程的单线程池

   ```java
   public static ExecutorService newSingleThreadExecutor() {
       return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1,0L, 
                                                      TimeUnit.MILLISECONDS,
                                   				   new LinkedBlockingQueue<Runnable>()));
   }
   ```

   - 保证所有任务按照**指定顺序执行**，线程数固定为 1，任务数多于 1 时会放入无界队列排队，任务执行完毕，这唯一的线程也不会被释放
   - 适用场景：适用于任务量已知，相对耗时的任务

3. newCachedThreadPool：创建一个没有核心线程可扩容的线程池

   ```java
   public static ExecutorService newCachedThreadPool() {
       return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS,
                                     new SynchronousQueue<Runnable>());
   }
   ```

   - 核心线程数是 0， 最大线程数是 29 个 ，全部都是救急线程（60s 后可以回收），可能会创建大量线程，从而导致 **OOM**
   - SynchronousQueue 作为阻塞队列，没有容量，对于每一个 take 的线程会阻塞直到有一个 put 的线程放入元素为止（类似一手交钱、一手交货）
   - 适用场景：适合任务数比较密集，但每个任务执行时间较短的情况


4. 使用newScheduledThreadPool创建一个指定核心线程数量的线程池，并且支持定时以及周期性任务执行，使用schedule提交任务

   ```java
   public ScheduledThreadPoolExecutor(int corePoolSize) {
       // 最大线程数固定为 Integer.MAX_VALUE，保活时间 keepAliveTime 固定为 0
       super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
             // 阻塞队列是 DelayedWorkQueue
             new DelayedWorkQueue());
   }
   ```

   - 指定核心线程数量，最大线程数固定为 Integer.MAX_VALUE，保活时间 keepAliveTime 固定为 0
   - 使用DelayedWorkQueue确保任务的优先级
   - 使用场景：延时任务或定时任务

对比：

- 创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，线程池会新建一个线程，保证池的正常工作

- Executors.newSingleThreadExecutor() 线程个数始终为 1，不能修改。FinalizableDelegatedExecutorService 应用的是装饰器模式，只对外暴露了 ExecutorService 接口，因此不能调用 ThreadPoolExecutor 中特有的方法

  原因：父类不能直接调用子类中的方法，需要反射或者创建对象的方式，可以调用子类静态方法

- Executors.newFixedThreadPool(1) 初始时为 1，可以修改。对外暴露的是 ThreadPoolExecutor 对象，可以强转后调用 setCorePoolSize 等方法进行修改

### 3.8 为什么不建议使用Executors创建线程池

- newFixedThreadPool 和 newSingleThreadExecutor 使用的是LinkedBlockingQueue作为阻塞队列，并且使用的是默认容量Integer.MAX_VALUE，可能会堆积大量请求，造成OOM
- newCachedThreadPool 和 newScheduledThreadPool 最大线程数是Integer.MAX_VALUE，可能会创建大量线程

线程资源必须通过线程池提供，不允许在应用中自行显式创建线程

- 使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题
- 如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者过度切换的问题
- 线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式更加明确线程池的运行规则，规避资源耗尽的风险



### 3.9 execute() vs submit()

excute()方法用于**提交不需要返回值的任务**，所以无法判断任务是否被线程池成功执行。

submit()方法用于**提交需要返回值的任务**，线程池会返回一个Future类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 get()方法来获取返回值，**get()方法会阻塞当前线程直到任务完成**，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。



### 3.10 shutdown() vs shutdownNow()

shutdown（）：关闭线程池，线程池的状态变为 **SHUTDOWN**。**线程池不再接受新任务了，但是队列里的任务得执行完毕**。
shutdownNow（）：关闭线程池，线程的状态变为 **STOP**。**线程池会终止当前正在运行的任务，并停止处理排队的任务并返回正在等待执行的 List**。



### 3.11 isTerminated() vs isShutdown()

isShutDown 当调用 shutdown() 方法后返回为 true。
isTerminated 当调用 shutdown() 方法后，并且**所有提交的任务完成后返回为 true**。

### 3.12  CountDownLatch

CountDownLatch（闭锁/倒计时锁）用来进行线程同步协作，等待所有线程完成倒计时（一个或者多个线程，等待其他多个线程完成某件事情之后才能执行）

- 其中构造参数用来初始化等待计数值
- await() 用来等待计数归零
- countDown() 用来让计数减一

```java
CountDownLatch latch = new CountDownLatch(3);
latch.countDown();
latch.await();
```

#### 3.12.1 es数据批量导入

需要把数据库中的数据一次性的同步到es索引库中，但是当时的数据好像是1000万左右，一次性读取数据肯定不行（oom异常），当时我就想到可以使用线程池的方式导入，利用CountDownLatch来控制，就能避免一次性加载过多，防止内存溢出

整体流程就是通过CountDownLatch+线程池配合去执行

### 3.13 Future

在实际开发的过程中，难免需要调用多个接口来汇总数据，如果所有接口（或部分接口）的没有依赖关系，就可以使用线程池+future来提升性能

#### 3.13.1 数据汇总

在一个电商网站中，用户下单之后，需要查询数据，数据包含了三部分：订单信息、包含的商品、物流信息；这三块信息都在不同的微服务中进行实现的，我们如何完成这个业务呢？



### 3.14 如何控制某个方法允许并发访问线程的数量

Semaphore 信号量，是JUC包下的一个工具类，我们可以通过其限制执行的线程数量，达到限流的效果
当一个线程执行时先通过其方法进行获取许可操作，获取到许可的线程继续执行业务逻辑，当线程执行完成后进行释放许可操作，未获取达到许可的线程进行等待或者直接结束。

Semaphore两个重要的方法

- lsemaphore.acquire()： 请求一个信号量，这时候的信号量个数-1（一旦没有可使用的信号量，也即信号量个数变为负数时，再次请求的时候就会阻塞，直到其他线程释放了信号量）
- lsemaphore.release()：释放一个信号量，此时信号量个数+1



### 3.15 ThreadLocal

ThreadLocal是多线程中对于解决线程安全的一个操作类，它会为每个线程都分配一个独立的线程副本从而解决了变量并发访问冲突的问题。ThreadLocal 同时实现了线程内的资源共享

#### 3.15.1 场景-JDBC连接数据库

案例：使用JDBC操作数据库时，会将每一个线程的Connection放入各自的ThreadLocal中，从而保证每个线程都在各自的 Connection 上进行数据库的操作，避免A线程关闭了B线程的连接。

####  3.15.2 ThreadLocal-内存泄露问题

每一个Thread维护一个ThreadLocalMap，在ThreadLocalMap中的Entry对象继承了WeakReference。其中key为使用弱引用的ThreadLocal实例，value为线程变量的副本；弱引用在内存不够的时候，会进行回收

因此在使用ThreadLocal的时候，需要手动手动remove

## 4 JUC

### 4.1 主内存模型

由于程序运行过程中的临时数据是存放在**主存（物理内存）**当中的，这时就存在⼀个问题，**由于 CPU 执⾏行速度很快，⽽从内存读取数据和向内存写⼊入数据的过程跟 CPU 执行指令的速度⽐起来要慢的多，因此如果任何时候对数据的操作都要通过和物理内存的交互来进行会⼤大降低指令执行的速度。**

为了了处理这个问题，在 CPU⾥面就有了**⾼速缓存(Cache)**的概念。当程序在运行过程中，会将运算需要的数据从主存复制⼀份到 CPU 的⾼速缓存当中，那么 CPU 进行计算时就可以直接从它的高速缓存读取数据和向其中写⼊数据，当运算结束之后，再将⾼速缓存中的数据刷新到主存当中。

加入高速缓存带来了一个新的问题：**缓存一致性。**如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。

所有的变量都存储在**主内存**中，每个线程还有自己的**工作内存**，**工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝**。

线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。

#### 4.1.1 内存间的交互操作

![输入图片说明](https://foruda.gitee.com/images/1691828255372205030/60bc5f77_8616658.png "内存间的交互操作")

read：把一个变量的值从主内存传输到工作内存中
load：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中
use：把工作内存中一个变量的值传递给执行引擎
assign：把一个从执行引擎接收到的值赋给工作内存的变量
store：把工作内存的一个变量的值传送到主内存中
write：在 store 之后执行，把 store 得到的值放入主内存的变量中
lock：作用于主内存的变量
unlock 

#### 4.1.2 内存模型三大特性

- **原子性：**即⼀个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

- **可见性：**可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。

- **有序性：**在本线程内观察，所有操作都是有序的；在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排。

  在 Java 内存模型中，允许**编译器和处理器**对指令进行重排序，**重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性**。

### 4.2 CAS

CAS的全称是：Compare And Swap(比较再交换)，它体现的一种乐观锁的思想，在无锁情况下保证线程操作共享数据的原子性，在操作的是使用一种乐观锁的思想，底层依赖于一个Unsafe类来直接调用操作系统底层的CAS指令。

#### 4.2.1 基本流程

CAS指令需要三个参数，一个当前主内存值V、旧的预期值A、即将更新的值B，当且仅当旧的预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做，并返回false。如果CAS操作失败，通过自旋的方式等待并再次尝试，直到成功

#### 4.2.2 底层实现

CAS底层依赖于一个Unsafe类来直接调用操作系统底层的CAS指令，都是native修饰的方法，由系统提供的接口执行，并非java代码实现，一般的思路也都是自旋锁实现



### 4.3 volatile

volatile用来修饰共享变量，保证变量在多线程之间操作的**可见性**和**有序性**。

#### 4.3.1 可见性的实现

保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的,volatile关键字会强制将修改的值立即写入主存。

- 写屏障：在该屏障之前的，对volatile变量的所有改动都将同步到主存中
- 读屏障：在该屏障之后的，对共享变量的读取都是重新加载主存中的数据

#### 4.3.2 有序性

用 volatile 修饰共享变量会在读、写共享变量时会加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果

- 写屏障；不会将写屏障之前的代码排在写屏障之后
- 读屏障：不会将读屏障之后的代码排在读屏障之前



### 4.4 AQS

AQS：AbstractQueuedSynchronizer，是多线程的抽象队列同步器，是**阻塞式锁**和相关的同步器工具的框架，许多同步类实现都依赖于该同步器，其中ReentrantLock、Semaphore、CountDownLatch都是基于AQS实现的。

#### 4.4.1 基本机制

在AQS内部有一个volatile修饰属性state，这个属性相当于是一个资源，有两种状态，默认是0，表示无锁状态，如果队列中有一个线程将state成功修改为1，则表示当前线程获取了资源。当有多个线程对state进行修改的时候，使用cas操作来保证修改的原子性。

在AQS中还维护了一个FIFO的双向队列，head头节点表示最先到达的线程，尾节点tail。

当当前线程执行完后，释放锁，会将state状态改为0，并唤醒队列中的head元素。

#### 4.4.2 AQS是公平锁还是非公平锁

- 新的线程与队列中的线程共同来抢资源，是非公平锁
- 新的线程到队列中等待，只让队列中的head线程获取锁，是公平锁

AQS实现类ReentrantLock，它默认就是非公平锁，新的线程与队列中的线程共同来抢资源



### 4.5  ReentrantLock

可重入互斥锁，其基本行为和语义与使用同步方法和语句访问的隐式监视器锁相同，但具有扩展功能，**可中断、可以设置超时时间、可以设置公平锁、支持多个条件变量**。

#### 4.5.1 基本实现原理

ReentrantLock主要利用CAS+AQS队列来实现。构造方法接受一个可选的公平参数（默认非公平锁），当设置为true时，表示公平锁，否则为非公平锁。公平锁的效率往往没有非公平锁的效率高，在许多线程访问的情况下，公平锁表现出较低的吞吐量。

#### 4.5.2 synchronized 和 lock区别

- 语法层面：
  - synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现；Lock 是接口，源码由 jdk 提供，用 java 语言实现；
  - 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁
- 功能层面：
  - 二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能
  - Lock 提供了许多 synchronized 不具备的功能，例如获取等待状态、公平锁、可打断、可超时、多条件变量
  - Lock 有适合不同场景的实现，如 ReentrantLock，ReentrantReadWriteLock
- 性能层面：在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖；在竞争激烈时，Lock 的实现通常会提供更好的性能



### 4.6 死锁

一个线程需要同时获取多把锁，这时就容易发生死锁

#### 4.6.1 死锁如何解决

使用jdk自带的工具：jps和 jstack

- jps 查看JVM中运行的**进程状态**信息（进程Id、进程名字）
- jstack 查看Java**线程堆栈**的信息（`jstack -l 进程Id`显示线程哪里出现死锁，线程拥有的锁和线程所需要的锁）

根据jstack找到死锁位置，根据日志提示信息，找到可能会死锁产生的位置代码，检查代码

其他工具：

- jconsole

  用于对jvm的**内存，线程，类**的监控，是一个基于 jmx 的 GUI 性能监控工具

  打开方式：java 安装目录 bin目录下，直接启动 jconsole.exe 就行

- VisualVM：故障处理工具

  能够监控线程，内存情况，查看方法的CPU时间和内存中的对象，已被GC的对象，反向查看分配的堆栈，可以根据dump查看详细信息

  打开方式：java 安装目录 bin目录下，直接启动 jvisualvm.exe就行

***



## 5 ConcurrentHashMap 

### 5.1 集合对比

三种集合：

- HashMap 是线程不安全的，性能好
- Hashtable 线程安全基于 synchronized，综合性能差，已经被淘汰
- ConcurrentHashMap 保证了线程安全，综合性能较好，不止线程安全，而且效率高，性能好

集合对比：

1. Hashtable 继承 Dictionary 类，HashMap、ConcurrentHashMap 继承 AbstractMap，均实现 Map 接口
2. Hashtable 底层是数组 + 链表，JDK8 以后 HashMap 和 ConcurrentHashMap 底层是数组 + 链表 + 红黑树
3. HashMap 线程非安全，Hashtable 线程安全，Hashtable 的方法都加了 synchronized 关来确保线程同步
4. ConcurrentHashMap、Hashtable **不允许 null 值**，HashMap 允许 null 值
5. ConcurrentHashMap、HashMap 的初始容量为 16，Hashtable 初始容量为11，填充因子默认都是 0.75，两种 Map 扩容是当前容量翻倍：capacity * 2，Hashtable 扩容时是容量翻倍 + 1：capacity*2 + 1

### 5.2 基本流程

![输入图片说明](https://foruda.gitee.com/images/1679294599328788708/ebb08713_8616658.png "屏幕截图")

工作步骤：

1. 初始化，使用 cas 来保证并发安全，懒惰初始化 table

2. 树化，当 table.length < 64 时，先尝试扩容，超过 64 时，并且 bin.length > 8 时，会将**链表树化**，树化过程会用 synchronized 锁住链表头

   说明：锁住某个槽位的对象头，是一种很好的**细粒度的加锁**方式，类似 MySQL 中的行锁

3. put，如果该 bin 尚未创建，只需要使用 cas 创建 bin；如果已经有了，锁住链表头进行后续 put 操作，元素添加至 bin 的尾部

4. get，无锁操作仅需要保证可见性，扩容过程中 get 操作拿到的是 ForwardingNode 会让 get 操作在新 table 进行搜索

5. 扩容，扩容时以 bin 为单位进行，需要对 bin 进行 synchronized，但这时其它竞争线程也不是无事可做，它们会帮助把其它 bin 进行扩容

6. size，元素个数保存在 baseCount 中，并发时的个数变动保存在 CounterCell[] 当中，最后统计数量时累加